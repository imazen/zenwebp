//! Cost estimation for VP8 encoding
//!
//! This module provides rate-distortion (RD) cost calculation for mode selection,
//! based on libwebp's cost estimation approach.
//!
//! The key insight is that encoding cost depends on:
//! 1. Mode signaling cost (fixed per mode type)
//! 2. Coefficient encoding cost (depends on coefficient values and probabilities)
//!
//! For mode selection, we use: score = Distortion + lambda * Rate

// Allow unused items - these tables and functions are part of the complete libwebp
// cost estimation system and will be used as additional features are implemented.
#![allow(dead_code)]

/// Distortion multiplier - scales distortion to match bit cost units
pub const RD_DISTO_MULT: u32 = 256;

//------------------------------------------------------------------------------
// Entropy cost table
//
// VP8EntropyCost[i] = -log2(i/255) * 256, scaled for integer arithmetic.
// This gives the bit cost for coding a boolean with probability i/255.

/// Entropy cost lookup table: cost = -log2(prob) * 256
/// Index is probability (0-255), value is cost in 1/256 bits.
pub const VP8_ENTROPY_COST: [u16; 256] = [
    1792, 1792, 1792, 1536, 1536, 1408, 1366, 1280, 1280, 1216, 1178, 1152, 1110, 1076, 1061, 1024,
    1024, 992, 968, 951, 939, 911, 896, 878, 871, 854, 838, 820, 811, 794, 786, 768, 768, 752, 740,
    732, 720, 709, 704, 690, 683, 672, 666, 655, 647, 640, 631, 622, 615, 607, 598, 592, 586, 576,
    572, 564, 559, 555, 547, 541, 534, 528, 522, 512, 512, 504, 500, 494, 488, 483, 477, 473, 467,
    461, 458, 452, 448, 443, 438, 434, 427, 424, 419, 415, 410, 406, 403, 399, 394, 390, 384, 384,
    377, 374, 370, 366, 362, 359, 355, 351, 347, 342, 342, 336, 333, 330, 326, 323, 320, 316, 312,
    308, 305, 302, 299, 296, 293, 288, 287, 283, 280, 277, 274, 272, 268, 266, 262, 256, 256, 256,
    251, 248, 245, 242, 240, 237, 234, 232, 228, 226, 223, 221, 218, 216, 214, 211, 208, 205, 203,
    201, 198, 196, 192, 191, 188, 187, 183, 181, 179, 176, 175, 171, 171, 168, 165, 163, 160, 159,
    156, 154, 152, 150, 148, 146, 144, 142, 139, 138, 135, 133, 131, 128, 128, 125, 123, 121, 119,
    117, 115, 113, 111, 110, 107, 105, 103, 102, 100, 98, 96, 94, 92, 91, 89, 86, 86, 83, 82, 80,
    77, 76, 74, 73, 71, 69, 67, 66, 64, 63, 61, 59, 57, 55, 54, 52, 51, 49, 47, 46, 44, 43, 41, 40,
    38, 36, 35, 33, 32, 30, 29, 27, 25, 24, 22, 21, 19, 18, 16, 15, 13, 12, 10, 9, 7, 6, 4, 3,
];

/// Calculate bit cost for coding a boolean value with given probability.
///
/// Returns cost in 1/256 bit units.
#[inline]
pub fn vp8_bit_cost(bit: bool, prob: u8) -> u16 {
    if bit {
        VP8_ENTROPY_COST[255 - prob as usize]
    } else {
        VP8_ENTROPY_COST[prob as usize]
    }
}

//------------------------------------------------------------------------------
// Level cost table
//
// Fixed costs for encoding coefficient levels, independent of probability state.
// MAX_LEVEL = 2047

/// Maximum coefficient level
pub const MAX_LEVEL: usize = 2047;

/// Maximum variable level in the coding tree
pub const MAX_VARIABLE_LEVEL: usize = 67;

/// Fixed costs for coefficient levels 0..=2047
/// These costs are probability-independent and come from the VP8 coding tree structure.
#[rustfmt::skip]
pub const VP8_LEVEL_FIXED_COSTS: [u16; MAX_LEVEL + 1] = [
    0,    256,  256,  256,  256,  432,  618,  630,  731,  640,  640,  828,
    901,  948,  1021, 1101, 1174, 1221, 1294, 1042, 1085, 1115, 1158, 1202,
    1245, 1275, 1318, 1337, 1380, 1410, 1453, 1497, 1540, 1570, 1613, 1280,
    1295, 1317, 1332, 1358, 1373, 1395, 1410, 1454, 1469, 1491, 1506, 1532,
    1547, 1569, 1584, 1601, 1616, 1638, 1653, 1679, 1694, 1716, 1731, 1775,
    1790, 1812, 1827, 1853, 1868, 1890, 1905, 1727, 1733, 1742, 1748, 1759,
    1765, 1774, 1780, 1800, 1806, 1815, 1821, 1832, 1838, 1847, 1853, 1878,
    1884, 1893, 1899, 1910, 1916, 1925, 1931, 1951, 1957, 1966, 1972, 1983,
    1989, 1998, 2004, 2027, 2033, 2042, 2048, 2059, 2065, 2074, 2080, 2100,
    2106, 2115, 2121, 2132, 2138, 2147, 2153, 2178, 2184, 2193, 2199, 2210,
    2216, 2225, 2231, 2251, 2257, 2266, 2272, 2283, 2289, 2298, 2304, 2168,
    2174, 2183, 2189, 2200, 2206, 2215, 2221, 2241, 2247, 2256, 2262, 2273,
    2279, 2288, 2294, 2319, 2325, 2334, 2340, 2351, 2357, 2366, 2372, 2392,
    2398, 2407, 2413, 2424, 2430, 2439, 2445, 2468, 2474, 2483, 2489, 2500,
    2506, 2515, 2521, 2541, 2547, 2556, 2562, 2573, 2579, 2588, 2594, 2619,
    2625, 2634, 2640, 2651, 2657, 2666, 2672, 2692, 2698, 2707, 2713, 2724,
    2730, 2739, 2745, 2540, 2546, 2555, 2561, 2572, 2578, 2587, 2593, 2613,
    2619, 2628, 2634, 2645, 2651, 2660, 2666, 2691, 2697, 2706, 2712, 2723,
    2729, 2738, 2744, 2764, 2770, 2779, 2785, 2796, 2802, 2811, 2817, 2840,
    2846, 2855, 2861, 2872, 2878, 2887, 2893, 2913, 2919, 2928, 2934, 2945,
    2951, 2960, 2966, 2991, 2997, 3006, 3012, 3023, 3029, 3038, 3044, 3064,
    3070, 3079, 3085, 3096, 3102, 3111, 3117, 2981, 2987, 2996, 3002, 3013,
    3019, 3028, 3034, 3054, 3060, 3069, 3075, 3086, 3092, 3101, 3107, 3132,
    3138, 3147, 3153, 3164, 3170, 3179, 3185, 3205, 3211, 3220, 3226, 3237,
    3243, 3252, 3258, 3281, 3287, 3296, 3302, 3313, 3319, 3328, 3334, 3354,
    3360, 3369, 3375, 3386, 3392, 3401, 3407, 3432, 3438, 3447, 3453, 3464,
    3470, 3479, 3485, 3505, 3511, 3520, 3526, 3537, 3543, 3552, 3558, 2816,
    2822, 2831, 2837, 2848, 2854, 2863, 2869, 2889, 2895, 2904, 2910, 2921,
    2927, 2936, 2942, 2967, 2973, 2982, 2988, 2999, 3005, 3014, 3020, 3040,
    3046, 3055, 3061, 3072, 3078, 3087, 3093, 3116, 3122, 3131, 3137, 3148,
    3154, 3163, 3169, 3189, 3195, 3204, 3210, 3221, 3227, 3236, 3242, 3267,
    3273, 3282, 3288, 3299, 3305, 3314, 3320, 3340, 3346, 3355, 3361, 3372,
    3378, 3387, 3393, 3257, 3263, 3272, 3278, 3289, 3295, 3304, 3310, 3330,
    3336, 3345, 3351, 3362, 3368, 3377, 3383, 3408, 3414, 3423, 3429, 3440,
    3446, 3455, 3461, 3481, 3487, 3496, 3502, 3513, 3519, 3528, 3534, 3557,
    3563, 3572, 3578, 3589, 3595, 3604, 3610, 3630, 3636, 3645, 3651, 3662,
    3668, 3677, 3683, 3708, 3714, 3723, 3729, 3740, 3746, 3755, 3761, 3781,
    3787, 3796, 3802, 3813, 3819, 3828, 3834, 3629, 3635, 3644, 3650, 3661,
    3667, 3676, 3682, 3702, 3708, 3717, 3723, 3734, 3740, 3749, 3755, 3780,
    3786, 3795, 3801, 3812, 3818, 3827, 3833, 3853, 3859, 3868, 3874, 3885,
    3891, 3900, 3906, 3929, 3935, 3944, 3950, 3961, 3967, 3976, 3982, 4002,
    4008, 4017, 4023, 4034, 4040, 4049, 4055, 4080, 4086, 4095, 4101, 4112,
    4118, 4127, 4133, 4153, 4159, 4168, 4174, 4185, 4191, 4200, 4206, 4070,
    4076, 4085, 4091, 4102, 4108, 4117, 4123, 4143, 4149, 4158, 4164, 4175,
    4181, 4190, 4196, 4221, 4227, 4236, 4242, 4253, 4259, 4268, 4274, 4294,
    4300, 4309, 4315, 4326, 4332, 4341, 4347, 4370, 4376, 4385, 4391, 4402,
    4408, 4417, 4423, 4443, 4449, 4458, 4464, 4475, 4481, 4490, 4496, 4521,
    4527, 4536, 4542, 4553, 4559, 4568, 4574, 4594, 4600, 4609, 4615, 4626,
    4632, 4641, 4647, 3515, 3521, 3530, 3536, 3547, 3553, 3562, 3568, 3588,
    3594, 3603, 3609, 3620, 3626, 3635, 3641, 3666, 3672, 3681, 3687, 3698,
    3704, 3713, 3719, 3739, 3745, 3754, 3760, 3771, 3777, 3786, 3792, 3815,
    3821, 3830, 3836, 3847, 3853, 3862, 3868, 3888, 3894, 3903, 3909, 3920,
    3926, 3935, 3941, 3966, 3972, 3981, 3987, 3998, 4004, 4013, 4019, 4039,
    4045, 4054, 4060, 4071, 4077, 4086, 4092, 3956, 3962, 3971, 3977, 3988,
    3994, 4003, 4009, 4029, 4035, 4044, 4050, 4061, 4067, 4076, 4082, 4107,
    4113, 4122, 4128, 4139, 4145, 4154, 4160, 4180, 4186, 4195, 4201, 4212,
    4218, 4227, 4233, 4256, 4262, 4271, 4277, 4288, 4294, 4303, 4309, 4329,
    4335, 4344, 4350, 4361, 4367, 4376, 4382, 4407, 4413, 4422, 4428, 4439,
    4445, 4454, 4460, 4480, 4486, 4495, 4501, 4512, 4518, 4527, 4533, 4328,
    4334, 4343, 4349, 4360, 4366, 4375, 4381, 4401, 4407, 4416, 4422, 4433,
    4439, 4448, 4454, 4479, 4485, 4494, 4500, 4511, 4517, 4526, 4532, 4552,
    4558, 4567, 4573, 4584, 4590, 4599, 4605, 4628, 4634, 4643, 4649, 4660,
    4666, 4675, 4681, 4701, 4707, 4716, 4722, 4733, 4739, 4748, 4754, 4779,
    4785, 4794, 4800, 4811, 4817, 4826, 4832, 4852, 4858, 4867, 4873, 4884,
    4890, 4899, 4905, 4769, 4775, 4784, 4790, 4801, 4807, 4816, 4822, 4842,
    4848, 4857, 4863, 4874, 4880, 4889, 4895, 4920, 4926, 4935, 4941, 4952,
    4958, 4967, 4973, 4993, 4999, 5008, 5014, 5025, 5031, 5040, 5046, 5069,
    5075, 5084, 5090, 5101, 5107, 5116, 5122, 5142, 5148, 5157, 5163, 5174,
    5180, 5189, 5195, 5220, 5226, 5235, 5241, 5252, 5258, 5267, 5273, 5293,
    5299, 5308, 5314, 5325, 5331, 5340, 5346, 4604, 4610, 4619, 4625, 4636,
    4642, 4651, 4657, 4677, 4683, 4692, 4698, 4709, 4715, 4724, 4730, 4755,
    4761, 4770, 4776, 4787, 4793, 4802, 4808, 4828, 4834, 4843, 4849, 4860,
    4866, 4875, 4881, 4904, 4910, 4919, 4925, 4936, 4942, 4951, 4957, 4977,
    4983, 4992, 4998, 5009, 5015, 5024, 5030, 5055, 5061, 5070, 5076, 5087,
    5093, 5102, 5108, 5128, 5134, 5143, 5149, 5160, 5166, 5175, 5181, 5045,
    5051, 5060, 5066, 5077, 5083, 5092, 5098, 5118, 5124, 5133, 5139, 5150,
    5156, 5165, 5171, 5196, 5202, 5211, 5217, 5228, 5234, 5243, 5249, 5269,
    5275, 5284, 5290, 5301, 5307, 5316, 5322, 5345, 5351, 5360, 5366, 5377,
    5383, 5392, 5398, 5418, 5424, 5433, 5439, 5450, 5456, 5465, 5471, 5496,
    5502, 5511, 5517, 5528, 5534, 5543, 5549, 5569, 5575, 5584, 5590, 5601,
    5607, 5616, 5622, 5417, 5423, 5432, 5438, 5449, 5455, 5464, 5470, 5490,
    5496, 5505, 5511, 5522, 5528, 5537, 5543, 5568, 5574, 5583, 5589, 5600,
    5606, 5615, 5621, 5641, 5647, 5656, 5662, 5673, 5679, 5688, 5694, 5717,
    5723, 5732, 5738, 5749, 5755, 5764, 5770, 5790, 5796, 5805, 5811, 5822,
    5828, 5837, 5843, 5868, 5874, 5883, 5889, 5900, 5906, 5915, 5921, 5941,
    5947, 5956, 5962, 5973, 5979, 5988, 5994, 5858, 5864, 5873, 5879, 5890,
    5896, 5905, 5911, 5931, 5937, 5946, 5952, 5963, 5969, 5978, 5984, 6009,
    6015, 6024, 6030, 6041, 6047, 6056, 6062, 6082, 6088, 6097, 6103, 6114,
    6120, 6129, 6135, 6158, 6164, 6173, 6179, 6190, 6196, 6205, 6211, 6231,
    6237, 6246, 6252, 6263, 6269, 6278, 6284, 6309, 6315, 6324, 6330, 6341,
    6347, 6356, 6362, 6382, 6388, 6397, 6403, 6414, 6420, 6429, 6435, 3515,
    3521, 3530, 3536, 3547, 3553, 3562, 3568, 3588, 3594, 3603, 3609, 3620,
    3626, 3635, 3641, 3666, 3672, 3681, 3687, 3698, 3704, 3713, 3719, 3739,
    3745, 3754, 3760, 3771, 3777, 3786, 3792, 3815, 3821, 3830, 3836, 3847,
    3853, 3862, 3868, 3888, 3894, 3903, 3909, 3920, 3926, 3935, 3941, 3966,
    3972, 3981, 3987, 3998, 4004, 4013, 4019, 4039, 4045, 4054, 4060, 4071,
    4077, 4086, 4092, 3956, 3962, 3971, 3977, 3988, 3994, 4003, 4009, 4029,
    4035, 4044, 4050, 4061, 4067, 4076, 4082, 4107, 4113, 4122, 4128, 4139,
    4145, 4154, 4160, 4180, 4186, 4195, 4201, 4212, 4218, 4227, 4233, 4256,
    4262, 4271, 4277, 4288, 4294, 4303, 4309, 4329, 4335, 4344, 4350, 4361,
    4367, 4376, 4382, 4407, 4413, 4422, 4428, 4439, 4445, 4454, 4460, 4480,
    4486, 4495, 4501, 4512, 4518, 4527, 4533, 4328, 4334, 4343, 4349, 4360,
    4366, 4375, 4381, 4401, 4407, 4416, 4422, 4433, 4439, 4448, 4454, 4479,
    4485, 4494, 4500, 4511, 4517, 4526, 4532, 4552, 4558, 4567, 4573, 4584,
    4590, 4599, 4605, 4628, 4634, 4643, 4649, 4660, 4666, 4675, 4681, 4701,
    4707, 4716, 4722, 4733, 4739, 4748, 4754, 4779, 4785, 4794, 4800, 4811,
    4817, 4826, 4832, 4852, 4858, 4867, 4873, 4884, 4890, 4899, 4905, 4769,
    4775, 4784, 4790, 4801, 4807, 4816, 4822, 4842, 4848, 4857, 4863, 4874,
    4880, 4889, 4895, 4920, 4926, 4935, 4941, 4952, 4958, 4967, 4973, 4993,
    4999, 5008, 5014, 5025, 5031, 5040, 5046, 5069, 5075, 5084, 5090, 5101,
    5107, 5116, 5122, 5142, 5148, 5157, 5163, 5174, 5180, 5189, 5195, 5220,
    5226, 5235, 5241, 5252, 5258, 5267, 5273, 5293, 5299, 5308, 5314, 5325,
    5331, 5340, 5346, 4604, 4610, 4619, 4625, 4636, 4642, 4651, 4657, 4677,
    4683, 4692, 4698, 4709, 4715, 4724, 4730, 4755, 4761, 4770, 4776, 4787,
    4793, 4802, 4808, 4828, 4834, 4843, 4849, 4860, 4866, 4875, 4881, 4904,
    4910, 4919, 4925, 4936, 4942, 4951, 4957, 4977, 4983, 4992, 4998, 5009,
    5015, 5024, 5030, 5055, 5061, 5070, 5076, 5087, 5093, 5102, 5108, 5128,
    5134, 5143, 5149, 5160, 5166, 5175, 5181, 5045, 5051, 5060, 5066, 5077,
    5083, 5092, 5098, 5118, 5124, 5133, 5139, 5150, 5156, 5165, 5171, 5196,
    5202, 5211, 5217, 5228, 5234, 5243, 5249, 5269, 5275, 5284, 5290, 5301,
    5307, 5316, 5322, 5345, 5351, 5360, 5366, 5377, 5383, 5392, 5398, 5418,
    5424, 5433, 5439, 5450, 5456, 5465, 5471, 5496, 5502, 5511, 5517, 5528,
    5534, 5543, 5549, 5569, 5575, 5584, 5590, 5601, 5607, 5616, 5622, 5417,
    5423, 5432, 5438, 5449, 5455, 5464, 5470, 5490, 5496, 5505, 5511, 5522,
    5528, 5537, 5543, 5568, 5574, 5583, 5589, 5600, 5606, 5615, 5621, 5641,
    5647, 5656, 5662, 5673, 5679, 5688, 5694, 5717, 5723, 5732, 5738, 5749,
    5755, 5764, 5770, 5790, 5796, 5805, 5811, 5822, 5828, 5837, 5843, 5868,
    5874, 5883, 5889, 5900, 5906, 5915, 5921, 5941, 5947, 5956, 5962, 5973,
    5979, 5988, 5994, 5858, 5864, 5873, 5879, 5890, 5896, 5905, 5911, 5931,
    5937, 5946, 5952, 5963, 5969, 5978, 5984, 6009, 6015, 6024, 6030, 6041,
    6047, 6056, 6062, 6082, 6088, 6097, 6103, 6114, 6120, 6129, 6135, 6158,
    6164, 6173, 6179, 6190, 6196, 6205, 6211, 6231, 6237, 6246, 6252, 6263,
    6269, 6278, 6284, 6309, 6315, 6324, 6330, 6341, 6347, 6356, 6362, 6382,
    6388, 6397, 6403, 6414, 6420, 6429, 6435, 5303, 5309, 5318, 5324, 5335,
    5341, 5350, 5356, 5376, 5382, 5391, 5397, 5408, 5414, 5423, 5429, 5454,
    5460, 5469, 5475, 5486, 5492, 5501, 5507, 5527, 5533, 5542, 5548, 5559,
    5565, 5574, 5580, 5603, 5609, 5618, 5624, 5635, 5641, 5650, 5656, 5676,
    5682, 5691, 5697, 5708, 5714, 5723, 5729, 5754, 5760, 5769, 5775, 5786,
    5792, 5801, 5807, 5827, 5833, 5842, 5848, 5859, 5865, 5874, 5880, 5744,
    5750, 5759, 5765, 5776, 5782, 5791, 5797, 5817, 5823, 5832, 5838, 5849,
    5855, 5864, 5870, 5895, 5901, 5910, 5916, 5927, 5933, 5942, 5948, 5968,
    5974, 5983, 5989, 6000, 6006, 6015, 6021, 6044, 6050, 6059, 6065, 6076,
    6082, 6091, 6097, 6117, 6123, 6132, 6138, 6149, 6155, 6164, 6170, 6195,
    6201, 6210, 6216, 6227, 6233, 6242, 6248, 6268, 6274, 6283, 6289, 6300,
    6306, 6315, 6321, 6116, 6122, 6131, 6137, 6148, 6154, 6163, 6169, 6189,
    6195, 6204, 6210, 6221, 6227, 6236, 6242, 6267, 6273, 6282, 6288, 6299,
    6305, 6314, 6320, 6340, 6346, 6355, 6361, 6372, 6378, 6387, 6393, 6416,
    6422, 6431, 6437, 6448, 6454, 6463, 6469, 6489, 6495, 6504, 6510, 6521,
    6527, 6536, 6542, 6567, 6573, 6582, 6588, 6599, 6605, 6614, 6620, 6640,
    6646, 6655, 6661, 6672, 6678, 6687, 6693, 6557, 6563, 6572, 6578, 6589,
    6595, 6604, 6610, 6630, 6636, 6645, 6651, 6662, 6668, 6677, 6683, 6708,
    6714, 6723, 6729, 6740, 6746, 6755, 6761, 6781, 6787, 6796, 6802, 6813,
    6819, 6828, 6834, 6857, 6863, 6872, 6878, 6889, 6895, 6904, 6910, 6930,
    6936, 6945, 6951, 6962, 6968, 6977, 6983, 7008, 7014, 7023, 7029, 7040,
    7046, 7055, 7061, 7081, 7087, 7096, 7102, 7113, 7119, 7128, 7134, 6392,
    6398, 6407, 6413, 6424, 6430, 6439, 6445, 6465, 6471, 6480, 6486, 6497,
    6503, 6512, 6518, 6543, 6549, 6558, 6564, 6575, 6581, 6590, 6596, 6616,
    6622, 6631, 6637, 6648, 6654, 6663, 6669, 6692, 6698, 6707, 6713, 6724,
    6730, 6739, 6745, 6765, 6771, 6780, 6786, 6797, 6803, 6812, 6818, 6843,
    6849, 6858, 6864, 6875, 6881, 6890, 6896, 6916, 6922, 6931, 6937, 6948,
    6954, 6963, 6969, 6833, 6839, 6848, 6854, 6865, 6871, 6880, 6886, 6906,
    6912, 6921, 6927, 6938, 6944, 6953, 6959, 6984, 6990, 6999, 7005, 7016,
    7022, 7031, 7037, 7057, 7063, 7072, 7078, 7089, 7095, 7104, 7110, 7133,
    7139, 7148, 7154, 7165, 7171, 7180, 7186, 7206, 7212, 7221, 7227, 7238,
    7244, 7253, 7259, 7284, 7290, 7299, 7305, 7316, 7322, 7331, 7337, 7357,
    7363, 7372, 7378, 7389, 7395, 7404, 7410, 7205, 7211, 7220, 7226, 7237,
    7243, 7252, 7258, 7278, 7284, 7293, 7299, 7310, 7316, 7325, 7331, 7356,
    7362, 7371, 7377, 7388, 7394, 7403, 7409, 7429, 7435, 7444, 7450, 7461,
    7467, 7476, 7482, 7505, 7511, 7520, 7526, 7537, 7543, 7552, 7558, 7578,
    7584, 7593, 7599, 7610, 7616, 7625, 7631, 7656, 7662, 7671, 7677, 7688,
    7694, 7703, 7709, 7729, 7735, 7744, 7750, 7761,
];

/// Coefficient position to band mapping
pub const VP8_ENC_BANDS: [u8; 17] = [0, 1, 2, 3, 6, 4, 5, 6, 6, 6, 6, 6, 6, 6, 6, 7, 0];

//------------------------------------------------------------------------------
// Level codes for variable-length coefficient encoding

/// VP8LevelCodes table for encoding coefficient levels > 4
/// Format: [pattern, bits] where pattern encodes which probas to use
/// and bits encodes the actual bit values.
#[rustfmt::skip]
pub const VP8_LEVEL_CODES: [[u16; 2]; 67] = [
    [0x001, 0x000], [0x007, 0x001], [0x00f, 0x005], [0x00f, 0x00d],
    [0x033, 0x003], [0x033, 0x003], [0x033, 0x023], [0x033, 0x023],
    [0x033, 0x023], [0x033, 0x023], [0x0d3, 0x013], [0x0d3, 0x013],
    [0x0d3, 0x013], [0x0d3, 0x013], [0x0d3, 0x013], [0x0d3, 0x013],
    [0x0d3, 0x013], [0x0d3, 0x013], [0x0d3, 0x093], [0x0d3, 0x093],
    [0x0d3, 0x093], [0x0d3, 0x093], [0x0d3, 0x093], [0x0d3, 0x093],
    [0x0d3, 0x093], [0x0d3, 0x093], [0x0d3, 0x093], [0x0d3, 0x093],
    [0x0d3, 0x093], [0x0d3, 0x093], [0x0d3, 0x093], [0x0d3, 0x093],
    [0x0d3, 0x093], [0x0d3, 0x093], [0x153, 0x053], [0x153, 0x053],
    [0x153, 0x053], [0x153, 0x053], [0x153, 0x053], [0x153, 0x053],
    [0x153, 0x053], [0x153, 0x053], [0x153, 0x053], [0x153, 0x053],
    [0x153, 0x053], [0x153, 0x053], [0x153, 0x053], [0x153, 0x053],
    [0x153, 0x053], [0x153, 0x053], [0x153, 0x053], [0x153, 0x053],
    [0x153, 0x053], [0x153, 0x053], [0x153, 0x053], [0x153, 0x053],
    [0x153, 0x053], [0x153, 0x053], [0x153, 0x053], [0x153, 0x053],
    [0x153, 0x053], [0x153, 0x053], [0x153, 0x053], [0x153, 0x053],
    [0x153, 0x053], [0x153, 0x053], [0x153, 0x153],
];

//------------------------------------------------------------------------------
// Quantizer lookup tables

/// DC quantizer lookup table (index 0-127 -> quantizer step)
#[rustfmt::skip]
pub const VP8_DC_TABLE: [u16; 128] = [
    4, 5, 6, 7, 8, 9, 10, 10, 11, 12, 13, 14, 15, 16, 17, 17,
    18, 19, 20, 20, 21, 21, 22, 22, 23, 23, 24, 25, 25, 26, 27, 28,
    29, 30, 31, 32, 33, 34, 35, 36, 37, 37, 38, 39, 40, 41, 42, 43,
    44, 45, 46, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58,
    59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74,
    75, 76, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89,
    91, 93, 95, 96, 98, 100, 101, 102, 104, 106, 108, 110, 112, 114, 116, 118,
    122, 124, 126, 128, 130, 132, 134, 136, 138, 140, 143, 145, 148, 151, 154, 157,
];

/// AC quantizer lookup table (index 0-127 -> quantizer step)
#[rustfmt::skip]
pub const VP8_AC_TABLE: [u16; 128] = [
    4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,
    20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
    36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51,
    52, 53, 54, 55, 56, 57, 58, 60, 62, 64, 66, 68, 70, 72, 74, 76,
    78, 80, 82, 84, 86, 88, 90, 92, 94, 96, 98, 100, 102, 104, 106, 108,
    110, 112, 114, 116, 119, 122, 125, 128, 131, 134, 137, 140, 143, 146, 149, 152,
    155, 158, 161, 164, 167, 170, 173, 177, 181, 185, 189, 193, 197, 201, 205, 209,
    213, 217, 221, 225, 229, 234, 239, 245, 249, 254, 259, 264, 269, 274, 279, 284,
];

/// AC2 quantizer lookup table for Y2 block (index 0-127 -> quantizer step)
#[rustfmt::skip]
pub const VP8_AC_TABLE2: [u16; 128] = [
    8, 8, 9, 10, 12, 13, 15, 17, 18, 20, 21, 23, 24, 26, 27, 29,
    31, 32, 34, 35, 37, 38, 40, 41, 43, 44, 46, 48, 49, 51, 52, 54,
    55, 57, 58, 60, 62, 63, 65, 66, 68, 69, 71, 72, 74, 75, 77, 79,
    80, 82, 83, 85, 86, 88, 89, 93, 96, 99, 102, 105, 108, 111, 114, 117,
    120, 124, 127, 130, 133, 136, 139, 142, 145, 148, 151, 155, 158, 161, 164, 167,
    170, 173, 176, 179, 184, 189, 193, 198, 203, 207, 212, 217, 221, 226, 230, 235,
    240, 244, 249, 254, 258, 263, 268, 274, 280, 286, 292, 299, 305, 311, 317, 323,
    330, 336, 342, 348, 354, 362, 370, 379, 385, 393, 401, 409, 416, 424, 432, 440,
];

/// Zig-zag scan order for 4x4 block
pub const VP8_ZIGZAG: [usize; 16] = [0, 1, 4, 8, 5, 2, 3, 6, 9, 12, 13, 10, 7, 11, 14, 15];

/// Frequency-based sharpening weights
#[rustfmt::skip]
pub const VP8_FREQ_SHARPENING: [u8; 16] = [
    0, 30, 60, 90, 30, 60, 90, 90,
    60, 90, 90, 90, 90, 90, 90, 90,
];

/// Trellis distortion weights (for USE_TDISTO=1)
#[rustfmt::skip]
pub const VP8_WEIGHT_TRELLIS: [u16; 16] = [
    30, 27, 19, 11, 27, 24, 17, 10,
    19, 17, 12, 8, 11, 10, 8, 6,
];

//------------------------------------------------------------------------------
// Spectral distortion (TDisto) weights and functions
//
// These compute perceptual distortion using a Hadamard transform weighted
// by frequency importance. Used in full RD mode selection for better quality.
// Ported from libwebp src/dsp/enc.c

/// Spectral distortion weights for luma (kWeightY in libwebp)
/// Higher weights for low-frequency components (visually more important)
#[rustfmt::skip]
pub const VP8_WEIGHT_Y: [u16; 16] = [
    38, 32, 20,  9,
    32, 28, 17,  7,
    20, 17, 10,  4,
     9,  7,  4,  2,
];

/// Spectral distortion weights for chroma (kWeightUV in libwebp)
#[rustfmt::skip]
pub const VP8_WEIGHT_UV: [u16; 16] = [
    38, 32, 20,  9,
    32, 28, 17,  7,
    20, 17, 10,  4,
     9,  7,  4,  2,
];

/// Hadamard transform for a 4x4 block, weighted by w[].
/// Returns the sum of |transformed_coeff| * weight.
///
/// This is a 4x4 Hadamard (Walsh-Hadamard) transform that measures
/// frequency-weighted energy in the block.
///
/// # Arguments
/// * `input` - 4x4 block of pixels (accessed with given stride)
/// * `stride` - Row stride of input buffer
/// * `w` - 16 weights for frequency weighting
#[inline]
fn t_transform(input: &[u8], stride: usize, w: &[u16; 16]) -> i32 {
    let mut tmp = [0i32; 16];

    // Horizontal pass
    for i in 0..4 {
        let row = i * stride;
        let a0 = i32::from(input[row]) + i32::from(input[row + 2]);
        let a1 = i32::from(input[row + 1]) + i32::from(input[row + 3]);
        let a2 = i32::from(input[row + 1]) - i32::from(input[row + 3]);
        let a3 = i32::from(input[row]) - i32::from(input[row + 2]);
        tmp[i * 4] = a0 + a1;
        tmp[i * 4 + 1] = a3 + a2;
        tmp[i * 4 + 2] = a3 - a2;
        tmp[i * 4 + 3] = a0 - a1;
    }

    // Vertical pass with weighting
    let mut sum = 0i32;
    for i in 0..4 {
        let a0 = tmp[i] + tmp[8 + i];
        let a1 = tmp[4 + i] + tmp[12 + i];
        let a2 = tmp[4 + i] - tmp[12 + i];
        let a3 = tmp[i] - tmp[8 + i];
        let b0 = a0 + a1;
        let b1 = a3 + a2;
        let b2 = a3 - a2;
        let b3 = a0 - a1;

        sum += i32::from(w[i]) * b0.abs();
        sum += i32::from(w[4 + i]) * b1.abs();
        sum += i32::from(w[8 + i]) * b2.abs();
        sum += i32::from(w[12 + i]) * b3.abs();
    }
    sum
}

/// Compute spectral distortion between two 4x4 blocks.
///
/// Returns |TTransform(a) - TTransform(b)| >> 5
///
/// This measures the perceptual difference between blocks using
/// a frequency-weighted Hadamard transform.
///
/// # Arguments
/// * `a` - First 4x4 block (source)
/// * `b` - Second 4x4 block (prediction/reconstruction)
/// * `stride` - Row stride of both buffers
/// * `w` - 16 weights for frequency weighting
#[inline]
pub fn tdisto_4x4(a: &[u8], b: &[u8], stride: usize, w: &[u16; 16]) -> i32 {
    let sum1 = t_transform(a, stride, w);
    let sum2 = t_transform(b, stride, w);
    (sum2 - sum1).abs() >> 5
}

/// Compute spectral distortion between two 16x16 blocks.
///
/// Calls tdisto_4x4 16 times for each 4x4 sub-block.
///
/// # Arguments
/// * `a` - First 16x16 block (source)
/// * `b` - Second 16x16 block (prediction/reconstruction)
/// * `stride` - Row stride of both buffers
/// * `w` - 16 weights for frequency weighting
pub fn tdisto_16x16(a: &[u8], b: &[u8], stride: usize, w: &[u16; 16]) -> i32 {
    let mut d = 0i32;
    for y in 0..4 {
        for x in 0..4 {
            let offset = y * 4 * stride + x * 4;
            d += tdisto_4x4(&a[offset..], &b[offset..], stride, w);
        }
    }
    d
}

/// Compute spectral distortion between two 8x8 blocks (for chroma).
///
/// Calls tdisto_4x4 4 times for each 4x4 sub-block.
pub fn tdisto_8x8(a: &[u8], b: &[u8], stride: usize, w: &[u16; 16]) -> i32 {
    let mut d = 0i32;
    for y in 0..2 {
        for x in 0..2 {
            let offset = y * 4 * stride + x * 4;
            d += tdisto_4x4(&a[offset..], &b[offset..], stride, w);
        }
    }
    d
}

//------------------------------------------------------------------------------
// Flat source detection
//
// Detects if a 16x16 source block is "flat" (uniform color).
// Used to force DC mode at image edges to avoid prediction artifacts.

/// Check if a 16x16 source block is flat (all pixels same value).
///
/// Returns true if the first pixel value repeats throughout the block.
/// This is used for edge macroblocks where prediction from unavailable
/// neighbors would create artifacts.
///
/// # Arguments
/// * `src` - Source pixels (16x16 block accessed with given stride)
/// * `stride` - Row stride of source buffer
pub fn is_flat_source_16(src: &[u8], stride: usize) -> bool {
    let v = src[0];
    for y in 0..16 {
        let row = y * stride;
        for x in 0..16 {
            if src[row + x] != v {
                return false;
            }
        }
    }
    true
}

/// Check if quantized AC coefficients indicate a flat block.
///
/// Returns true if the number of non-zero AC coefficients is below threshold.
/// Used to detect flat content that should prefer DC mode.
///
/// # Arguments
/// * `levels` - Quantized coefficient levels (16 coeffs per block)
/// * `num_blocks` - Number of 4x4 blocks to check
/// * `thresh` - Maximum allowed non-zero AC coefficients
pub fn is_flat_coeffs(levels: &[i16], num_blocks: usize, thresh: i32) -> bool {
    let mut score = 0i32;
    for block in 0..num_blocks {
        // Skip DC (index 0), check AC coefficients (indices 1-15)
        for i in 1..16 {
            if levels[block * 16 + i] != 0 {
                score += 1;
                if score > thresh {
                    return false;
                }
            }
        }
    }
    true
}

/// Flatness threshold for I16 mode (FLATNESS_LIMIT_I16 in libwebp)
/// libwebp uses 0, which means "always check for flatness" in I16 mode
pub const FLATNESS_LIMIT_I16: i32 = 0;

/// Flatness threshold for I4 mode (FLATNESS_LIMIT_I4 in libwebp)
/// libwebp uses 3 (not 2)
pub const FLATNESS_LIMIT_I4: i32 = 3;

/// Flatness threshold for UV mode (FLATNESS_LIMIT_UV in libwebp)
pub const FLATNESS_LIMIT_UV: i32 = 2;

/// Flatness penalty added to rate when UV coefficients are flat (libwebp)
/// This discourages selection of non-DC modes when content is flat.
pub const FLATNESS_PENALTY: u32 = 140;

//------------------------------------------------------------------------------
// Quantization constants

/// Fixed-point precision for quantization
pub const QFIX: u32 = 17;

/// Bias calculation macro equivalent
#[inline]
pub const fn quantization_bias(b: u32) -> u32 {
    (((b) << (QFIX)) + 128) >> 8
}

/// Quantization division: (coeff * iq + bias) >> QFIX
#[inline]
pub fn quantdiv(coeff: u32, iq: u32, bias: u32) -> i32 {
    ((coeff as u64 * iq as u64 + bias as u64) >> QFIX) as i32
}

//------------------------------------------------------------------------------
// Filter strength calculation
//
// Ported from libwebp src/enc/filter_enc.c
// This table maps (sharpness, delta) to minimum filter strength needed.

/// Maximum delta size for filter strength lookup
const MAX_DELTA_SIZE: usize = 64;

/// Filter strength lookup table: [sharpness][delta] -> filter_level
/// This gives, for a given sharpness, the filtering strength to be
/// used (at least) in order to filter a given edge step delta.
/// Ported from libwebp's kLevelsFromDelta.
#[rustfmt::skip]
const LEVELS_FROM_DELTA: [[u8; MAX_DELTA_SIZE]; 8] = [
    [0,  1,  2,  3,  4,  5,  6,  7,  8,  9,  10, 11, 12, 13, 14, 15,
     16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31,
     32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47,
     48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63],
    [0,  1,  2,  3,  5,  6,  7,  8,  9,  11, 12, 13, 14, 15, 17, 18,
     20, 21, 23, 24, 26, 27, 29, 30, 32, 33, 35, 36, 38, 39, 41, 42,
     44, 45, 47, 48, 50, 51, 53, 54, 56, 57, 59, 60, 62, 63, 63, 63,
     63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63],
    [0,  1,  2,  3,  5,  6,  7,  8,  9,  11, 12, 13, 14, 16, 17, 19,
     20, 22, 23, 25, 26, 28, 29, 31, 32, 34, 35, 37, 38, 40, 41, 43,
     44, 46, 47, 49, 50, 52, 53, 55, 56, 58, 59, 61, 62, 63, 63, 63,
     63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63],
    [0,  1,  2,  3,  5,  6,  7,  8,  9,  11, 12, 13, 15, 16, 18, 19,
     21, 22, 24, 25, 27, 28, 30, 31, 33, 34, 36, 37, 39, 40, 42, 43,
     45, 46, 48, 49, 51, 52, 54, 55, 57, 58, 60, 61, 63, 63, 63, 63,
     63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63],
    [0,  1,  2,  3,  5,  6,  7,  8,  9,  11, 12, 14, 15, 17, 18, 20,
     21, 23, 24, 26, 27, 29, 30, 32, 33, 35, 36, 38, 39, 41, 42, 44,
     45, 47, 48, 50, 51, 53, 54, 56, 57, 59, 60, 62, 63, 63, 63, 63,
     63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63],
    [0,  1,  2,  4,  5,  7,  8,  9,  11, 12, 13, 15, 16, 17, 19, 20,
     22, 23, 25, 26, 28, 29, 31, 32, 34, 35, 37, 38, 40, 41, 43, 44,
     46, 47, 49, 50, 52, 53, 55, 56, 58, 59, 61, 62, 63, 63, 63, 63,
     63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63],
    [0,  1,  2,  4,  5,  7,  8,  9,  11, 12, 13, 15, 16, 18, 19, 21,
     22, 24, 25, 27, 28, 30, 31, 33, 34, 36, 37, 39, 40, 42, 43, 45,
     46, 48, 49, 51, 52, 54, 55, 57, 58, 60, 61, 63, 63, 63, 63, 63,
     63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63],
    [0,  1,  2,  4,  5,  7,  8,  9,  11, 12, 14, 15, 17, 18, 20, 21,
     23, 24, 26, 27, 29, 30, 32, 33, 35, 36, 38, 39, 41, 42, 44, 45,
     47, 48, 50, 51, 53, 54, 56, 57, 59, 60, 62, 63, 63, 63, 63, 63,
     63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63],
];

/// Cutoff for very small filter strengths (have close to no visual effect)
const FSTRENGTH_CUTOFF: u8 = 2;

/// Calculate filter strength from sharpness and edge delta.
/// Ported from libwebp's VP8FilterStrengthFromDelta.
#[inline]
pub fn filter_strength_from_delta(sharpness: u8, delta: u8) -> u8 {
    let pos = (delta as usize).min(MAX_DELTA_SIZE - 1);
    let sharpness_idx = (sharpness as usize).min(7);
    LEVELS_FROM_DELTA[sharpness_idx][pos]
}

/// Calculate optimal filter level based on quantizer and sharpness.
///
/// This implements libwebp's SetupFilterStrength logic:
/// 1. Compute qstep from AC quantizer
/// 2. Get base strength from delta table
/// 3. Scale by filter_strength config (default 50 = mid-filtering)
///
/// # Arguments
/// * `quant_index` - Quantizer index (0-127)
/// * `sharpness` - Sharpness level (0-7)
/// * `filter_strength` - User filter strength (0-100), default 50
pub fn compute_filter_level(quant_index: u8, sharpness: u8, filter_strength: u8) -> u8 {
    // level0 is in [0..500]. Using filter_strength=50 as mid-filtering.
    let level0 = 5 * filter_strength as u32;

    // Get AC quantizer step from the quant table and divide by 4
    let qstep = (VP8_AC_TABLE[quant_index as usize] >> 2) as u8;

    // Get base strength from delta table
    let base_strength = filter_strength_from_delta(sharpness, qstep) as u32;

    // Scale by level0 / 256 (simplified: we don't have per-segment beta)
    // In libwebp: f = base_strength * level0 / (256 + beta)
    // With beta=0, this simplifies to: f = base_strength * level0 / 256
    let f = (base_strength * level0) / 256;

    // Clamp to valid range and apply cutoff
    if f < FSTRENGTH_CUTOFF as u32 {
        0
    } else if f > 63 {
        63
    } else {
        f as u8
    }
}

//------------------------------------------------------------------------------
// Mode costs

/// Fixed mode costs for Intra16 modes (DC, V, H, TM)
/// These are pre-calculated bit costs from the VP8 coding tree.
/// Values from libwebp's VP8FixedCostsI16.
/// Note: these include the fixed VP8BitCost(1, 145) mode selection cost.
pub const FIXED_COSTS_I16: [u16; 4] = [663, 919, 872, 919];

/// Fixed mode costs for chroma modes (DC, V, H, TM)
/// Values from libwebp's VP8FixedCostsUV.
pub const FIXED_COSTS_UV: [u16; 4] = [302, 984, 439, 642];

/// Number of Intra4 prediction modes
pub const NUM_BMODES: usize = 10;

/// Context-dependent Intra4 mode costs.
/// Indexed as VP8_FIXED_COSTS_I4[top_mode][left_mode][mode].
/// From libwebp's VP8FixedCostsI4.
#[rustfmt::skip]
pub const VP8_FIXED_COSTS_I4: [[[u16; NUM_BMODES]; NUM_BMODES]; NUM_BMODES] = [
    [[40, 1151, 1723, 1874, 2103, 2019, 1628, 1777, 2226, 2137],
     [192, 469, 1296, 1308, 1849, 1794, 1781, 1703, 1713, 1522],
     [142, 910, 762, 1684, 1849, 1576, 1460, 1305, 1801, 1657],
     [559, 641, 1370, 421, 1182, 1569, 1612, 1725, 863, 1007],
     [299, 1059, 1256, 1108, 636, 1068, 1581, 1883, 869, 1142],
     [277, 1111, 707, 1362, 1089, 672, 1603, 1541, 1545, 1291],
     [214, 781, 1609, 1303, 1632, 2229, 726, 1560, 1713, 918],
     [152, 1037, 1046, 1759, 1983, 2174, 1358, 742, 1740, 1390],
     [512, 1046, 1420, 753, 752, 1297, 1486, 1613, 460, 1207],
     [424, 827, 1362, 719, 1462, 1202, 1199, 1476, 1199, 538]],
    [[240, 402, 1134, 1491, 1659, 1505, 1517, 1555, 1979, 2099],
     [467, 242, 960, 1232, 1714, 1620, 1834, 1570, 1676, 1391],
     [500, 455, 463, 1507, 1699, 1282, 1564, 982, 2114, 2114],
     [672, 643, 1372, 331, 1589, 1667, 1453, 1938, 996, 876],
     [458, 783, 1037, 911, 738, 968, 1165, 1518, 859, 1033],
     [504, 815, 504, 1139, 1219, 719, 1506, 1085, 1268, 1268],
     [333, 630, 1445, 1239, 1883, 3672, 799, 1548, 1865, 598],
     [399, 644, 746, 1342, 1856, 1350, 1493, 613, 1855, 1015],
     [622, 749, 1205, 608, 1066, 1408, 1290, 1406, 546, 971],
     [500, 753, 1041, 668, 1230, 1617, 1297, 1425, 1383, 523]],
    [[394, 553, 523, 1502, 1536, 981, 1608, 1142, 1666, 2181],
     [655, 430, 375, 1411, 1861, 1220, 1677, 1135, 1978, 1553],
     [690, 640, 245, 1954, 2070, 1194, 1528, 982, 1972, 2232],
     [559, 834, 741, 867, 1131, 980, 1225, 852, 1092, 784],
     [690, 875, 516, 959, 673, 894, 1056, 1190, 1528, 1126],
     [740, 951, 384, 1277, 1177, 492, 1579, 1155, 1846, 1513],
     [323, 775, 1062, 1776, 3062, 1274, 813, 1188, 1372, 655],
     [488, 971, 484, 1767, 1515, 1775, 1115, 503, 1539, 1461],
     [740, 1006, 998, 709, 851, 1230, 1337, 788, 741, 721],
     [522, 1073, 573, 1045, 1346, 887, 1046, 1146, 1203, 697]],
    [[105, 864, 1442, 1009, 1934, 1840, 1519, 1920, 1673, 1579],
     [534, 305, 1193, 683, 1388, 2164, 1802, 1894, 1264, 1170],
     [305, 518, 877, 1108, 1426, 3215, 1425, 1064, 1320, 1242],
     [683, 732, 1927, 257, 1493, 2048, 1858, 1552, 1055, 947],
     [394, 814, 1024, 660, 959, 1556, 1282, 1289, 893, 1047],
     [528, 615, 996, 940, 1201, 635, 1094, 2515, 803, 1358],
     [347, 614, 1609, 1187, 3133, 1345, 1007, 1339, 1017, 667],
     [218, 740, 878, 1605, 3650, 3650, 1345, 758, 1357, 1617],
     [672, 750, 1541, 558, 1257, 1599, 1870, 2135, 402, 1087],
     [592, 684, 1161, 430, 1092, 1497, 1475, 1489, 1095, 822]],
    [[228, 1056, 1059, 1368, 752, 982, 1512, 1518, 987, 1782],
     [494, 514, 818, 942, 965, 892, 1610, 1356, 1048, 1363],
     [512, 648, 591, 1042, 761, 991, 1196, 1454, 1309, 1463],
     [683, 749, 1043, 676, 841, 1396, 1133, 1138, 654, 939],
     [622, 1101, 1126, 994, 361, 1077, 1203, 1318, 877, 1219],
     [631, 1068, 857, 1650, 651, 477, 1650, 1419, 828, 1170],
     [555, 727, 1068, 1335, 3127, 1339, 820, 1331, 1077, 429],
     [504, 879, 624, 1398, 889, 889, 1392, 808, 891, 1406],
     [683, 1602, 1289, 977, 578, 983, 1280, 1708, 406, 1122],
     [399, 865, 1433, 1070, 1072, 764, 968, 1477, 1223, 678]],
    [[333, 760, 935, 1638, 1010, 529, 1646, 1410, 1472, 2219],
     [512, 494, 750, 1160, 1215, 610, 1870, 1868, 1628, 1169],
     [572, 646, 492, 1934, 1208, 603, 1580, 1099, 1398, 1995],
     [786, 789, 942, 581, 1018, 951, 1599, 1207, 731, 768],
     [690, 1015, 672, 1078, 582, 504, 1693, 1438, 1108, 2897],
     [768, 1267, 571, 2005, 1243, 244, 2881, 1380, 1786, 1453],
     [452, 899, 1293, 903, 1311, 3100, 465, 1311, 1319, 813],
     [394, 927, 942, 1103, 1358, 1104, 946, 593, 1363, 1109],
     [559, 1005, 1007, 1016, 658, 1173, 1021, 1164, 623, 1028],
     [564, 796, 632, 1005, 1014, 863, 2316, 1268, 938, 764]],
    [[266, 606, 1098, 1228, 1497, 1243, 948, 1030, 1734, 1461],
     [366, 585, 901, 1060, 1407, 1247, 876, 1134, 1620, 1054],
     [452, 565, 542, 1729, 1479, 1479, 1016, 886, 2938, 1150],
     [555, 1088, 1533, 950, 1354, 895, 834, 1019, 1021, 496],
     [704, 815, 1193, 971, 973, 640, 1217, 2214, 832, 578],
     [672, 1245, 579, 871, 875, 774, 872, 1273, 1027, 949],
     [296, 1134, 2050, 1784, 1636, 3425, 442, 1550, 2076, 722],
     [342, 982, 1259, 1846, 1848, 1848, 622, 568, 1847, 1052],
     [555, 1064, 1304, 828, 746, 1343, 1075, 1329, 1078, 494],
     [288, 1167, 1285, 1174, 1639, 1639, 833, 2254, 1304, 509]],
    [[342, 719, 767, 1866, 1757, 1270, 1246, 550, 1746, 2151],
     [483, 653, 694, 1509, 1459, 1410, 1218, 507, 1914, 1266],
     [488, 757, 447, 2979, 1813, 1268, 1654, 539, 1849, 2109],
     [522, 1097, 1085, 851, 1365, 1111, 851, 901, 961, 605],
     [709, 716, 841, 728, 736, 945, 941, 862, 2845, 1057],
     [512, 1323, 500, 1336, 1083, 681, 1342, 717, 1604, 1350],
     [452, 1155, 1372, 1900, 1501, 3290, 311, 944, 1919, 922],
     [403, 1520, 977, 2132, 1733, 3522, 1076, 276, 3335, 1547],
     [559, 1374, 1101, 615, 673, 2462, 974, 795, 984, 984],
     [547, 1122, 1062, 812, 1410, 951, 1140, 622, 1268, 651]],
    [[165, 982, 1235, 938, 1334, 1366, 1659, 1578, 964, 1612],
     [592, 422, 925, 847, 1139, 1112, 1387, 2036, 861, 1041],
     [403, 837, 732, 770, 941, 1658, 1250, 809, 1407, 1407],
     [896, 874, 1071, 381, 1568, 1722, 1437, 2192, 480, 1035],
     [640, 1098, 1012, 1032, 684, 1382, 1581, 2106, 416, 865],
     [559, 1005, 819, 914, 710, 770, 1418, 920, 838, 1435],
     [415, 1258, 1245, 870, 1278, 3067, 770, 1021, 1287, 522],
     [406, 990, 601, 1009, 1265, 1265, 1267, 759, 1017, 1277],
     [968, 1182, 1329, 788, 1032, 1292, 1705, 1714, 203, 1403],
     [732, 877, 1279, 471, 901, 1161, 1545, 1294, 755, 755]],
    [[111, 931, 1378, 1185, 1933, 1648, 1148, 1714, 1873, 1307],
     [406, 414, 1030, 1023, 1910, 1404, 1313, 1647, 1509, 793],
     [342, 640, 575, 1088, 1241, 1349, 1161, 1350, 1756, 1502],
     [559, 766, 1185, 357, 1682, 1428, 1329, 1897, 1219, 802],
     [473, 909, 1164, 771, 719, 2508, 1427, 1432, 722, 782],
     [342, 892, 785, 1145, 1150, 794, 1296, 1550, 973, 1057],
     [208, 1036, 1326, 1343, 1606, 3395, 815, 1455, 1618, 712],
     [228, 928, 890, 1046, 3499, 1711, 994, 829, 1720, 1318],
     [768, 724, 1058, 636, 991, 1075, 1319, 1324, 616, 825],
     [305, 1167, 1358, 899, 1587, 1587, 987, 1988, 1332, 501]],
];

//------------------------------------------------------------------------------
// Lambda calculation
//
// Lambda values control the rate-distortion trade-off.
// These are the fixed values from libwebp's RefineUsingDistortion.

/// Fixed lambda for Intra16 mode selection (distortion method)
pub const LAMBDA_I16: u32 = 106;

/// Fixed lambda for Intra4 mode selection (distortion method)
pub const LAMBDA_I4: u32 = 11;

/// Fixed lambda for UV mode selection (distortion method)
pub const LAMBDA_UV: u32 = 120;

/// Calculate lambda_i4 based on quantization: (3 * q²) >> 7
#[inline]
pub fn calc_lambda_i4(q: u32) -> u32 {
    ((3 * q * q) >> 7).max(1)
}

/// Calculate lambda_i16 based on quantization: 3 * q²
#[inline]
pub fn calc_lambda_i16(q: u32) -> u32 {
    (3 * q * q).max(1)
}

/// Calculate lambda_uv based on quantization: (3 * q²) >> 6
#[inline]
pub fn calc_lambda_uv(q: u32) -> u32 {
    ((3 * q * q) >> 6).max(1)
}

/// Calculate lambda_mode based on quantization: (1 * q²) >> 7
#[inline]
pub fn calc_lambda_mode(q: u32) -> u32 {
    ((q * q) >> 7).max(1)
}

/// Calculate i4_penalty based on quantization: 1000 * q²
/// This penalty accounts for the extra cost of Intra4 over Intra16.
#[inline]
pub fn calc_i4_penalty(q: u32) -> u64 {
    (1000 * q as u64 * q as u64).max(1)
}

/// Calculate trellis lambda for I16 mode: (q²) >> 2
#[inline]
pub fn calc_lambda_trellis_i16(q: u32) -> u32 {
    ((q * q) >> 2).max(1)
}

/// Calculate trellis lambda for I4 mode: (7 * q²) >> 3
#[inline]
pub fn calc_lambda_trellis_i4(q: u32) -> u32 {
    ((7 * q * q) >> 3).max(1)
}

/// Calculate trellis lambda for UV: (q²) << 1
#[inline]
pub fn calc_lambda_trellis_uv(q: u32) -> u32 {
    ((q * q) << 1).max(1)
}

/// Calculate tlambda (spectral distortion weight) based on SNS strength and quant.
///
/// tlambda = (sns_strength * q) >> 5
///
/// This controls how much weight spectral distortion (TDisto) has in mode selection.
/// Only enabled when method >= 4 and sns_strength > 0.
///
/// # Arguments
/// * `sns_strength` - Spatial noise shaping strength (0-100)
/// * `q` - Expanded quantization value (from VP8Matrix)
#[inline]
pub fn calc_tlambda(sns_strength: u32, q: u32) -> u32 {
    (sns_strength * q) >> 5
}

/// Default SNS strength value (matches libwebp default)
pub const DEFAULT_SNS_STRENGTH: u32 = 50;

//------------------------------------------------------------------------------
// Quantization matrix

/// Quantization matrix for a coefficient type (Y1, Y2, UV)
#[derive(Clone, Debug)]
pub struct VP8Matrix {
    /// Quantizer steps for each coefficient position
    pub q: [u16; 16],
    /// Reciprocals (1 << QFIX) / q, for fast division
    pub iq: [u32; 16],
    /// Rounding bias for quantization
    pub bias: [u32; 16],
    /// Zero threshold: coefficients below this are quantized to 0
    pub zthresh: [u32; 16],
    /// Sharpening boost for high-frequency coefficients
    pub sharpen: [u16; 16],
}

impl VP8Matrix {
    /// Create a new quantization matrix from DC and AC quantizer values
    pub fn new(q_dc: u16, q_ac: u16, matrix_type: MatrixType) -> Self {
        let bias_values = match matrix_type {
            MatrixType::Y1 => (96, 110),  // luma-ac
            MatrixType::Y2 => (96, 108),  // luma-dc
            MatrixType::UV => (110, 115), // chroma
        };

        let mut m = Self {
            q: [0; 16],
            iq: [0; 16],
            bias: [0; 16],
            zthresh: [0; 16],
            sharpen: [0; 16],
        };

        // Set DC (index 0) and AC (index 1+) values
        m.q[0] = q_dc;
        m.q[1] = q_ac;

        // Calculate reciprocals, bias, and zero thresholds for DC and AC
        for i in 0..2 {
            let is_ac = i > 0;
            let bias = if is_ac { bias_values.1 } else { bias_values.0 };
            m.iq[i] = ((1u64 << QFIX) / m.q[i] as u64) as u32;
            m.bias[i] = quantization_bias(bias);
            // zthresh: value such that quantdiv(coeff, iq, bias) is 0 if coeff <= zthresh
            m.zthresh[i] = ((1 << QFIX) - 1 - m.bias[i]) / m.iq[i];
        }

        // Replicate AC values for positions 2-15
        for i in 2..16 {
            m.q[i] = m.q[1];
            m.iq[i] = m.iq[1];
            m.bias[i] = m.bias[1];
            m.zthresh[i] = m.zthresh[1];
        }

        // Apply sharpening for Y1 matrix (luma AC)
        if matches!(matrix_type, MatrixType::Y1) {
            const SHARPEN_BITS: u32 = 11;
            for (i, &freq_sharpen) in VP8_FREQ_SHARPENING.iter().enumerate() {
                m.sharpen[i] = ((freq_sharpen as u32 * m.q[i] as u32) >> SHARPEN_BITS) as u16;
            }
        }

        m
    }

    /// Get the average quantizer value (for lambda calculations)
    pub fn average_q(&self) -> u32 {
        let sum: u32 = self.q.iter().map(|&x| x as u32).sum();
        (sum + 8) >> 4
    }

    /// Quantize a single coefficient
    #[inline]
    pub fn quantize_coeff(&self, coeff: i32, pos: usize) -> i32 {
        let sign = coeff < 0;
        let abs_coeff = if sign { -coeff } else { coeff } as u32;
        let level = quantdiv(abs_coeff, self.iq[pos], self.bias[pos]);
        if sign {
            -level
        } else {
            level
        }
    }

    /// Quantize a single coefficient with neutral bias (for trellis)
    #[inline]
    pub fn quantize_neutral(&self, coeff: i32, pos: usize) -> i32 {
        let sign = coeff < 0;
        let abs_coeff = if sign { -coeff } else { coeff } as u32;
        let neutral_bias = quantization_bias(0x00); // neutral
        let level = quantdiv(abs_coeff, self.iq[pos], neutral_bias);
        if sign {
            -level
        } else {
            level
        }
    }

    /// Dequantize a coefficient
    #[inline]
    pub fn dequantize(&self, level: i32, pos: usize) -> i32 {
        level * self.q[pos] as i32
    }

    /// Quantize an entire 4x4 block of coefficients in place
    pub fn quantize(&self, coeffs: &mut [i32; 16]) {
        for (pos, coeff) in coeffs.iter_mut().enumerate() {
            let sign = *coeff < 0;
            let abs_coeff = if sign { -*coeff } else { *coeff } as u32;
            let level = quantdiv(abs_coeff, self.iq[pos], self.bias[pos]);
            *coeff = if sign { -level } else { level };
        }
    }

    /// Quantize only AC coefficients (positions 1-15) in place, leaving DC unchanged
    /// This is used for Y1 blocks where the DC goes to the Y2 block
    pub fn quantize_ac_only(&self, coeffs: &mut [i32; 16]) {
        for pos in 1..16 {
            let sign = coeffs[pos] < 0;
            let abs_coeff = if sign { -coeffs[pos] } else { coeffs[pos] } as u32;
            let level = quantdiv(abs_coeff, self.iq[pos], self.bias[pos]);
            coeffs[pos] = if sign { -level } else { level };
        }
    }

    /// Dequantize an entire 4x4 block of coefficients in place
    pub fn dequantize_block(&self, coeffs: &mut [i32; 16]) {
        for (pos, coeff) in coeffs.iter_mut().enumerate() {
            *coeff *= self.q[pos] as i32;
        }
    }

    /// Dequantize only AC coefficients (positions 1-15) in place
    pub fn dequantize_ac_only(&self, coeffs: &mut [i32; 16]) {
        for pos in 1..16 {
            coeffs[pos] *= self.q[pos] as i32;
        }
    }
}

/// Matrix type for bias selection
#[derive(Clone, Copy, Debug)]
pub enum MatrixType {
    Y1, // Luma AC
    Y2, // Luma DC (WHT)
    UV, // Chroma
}

//------------------------------------------------------------------------------
// Trellis quantization

/// Maximum cost value for RD optimization
const MAX_COST: i64 = i64::MAX / 2;

/// Trellis node for dynamic programming
#[derive(Clone, Copy, Default)]
struct TrellisNode {
    prev: i8,   // best previous node (-1, 0, or 1 for delta)
    sign: bool, // sign of coefficient
    level: i16, // quantized level
}

/// Score state for trellis traversal
/// Stores score and a reference to cost table for the *next* position.
/// The cost table is determined by the context resulting from this state's level.
#[derive(Clone, Copy)]
struct TrellisScoreState<'a> {
    score: i64,                            // partial RD score
    costs: Option<&'a LevelCostArray>,     // cost table for next position (based on ctx from this level)
}

impl Default for TrellisScoreState<'_> {
    fn default() -> Self {
        Self {
            score: MAX_COST,
            costs: None,
        }
    }
}

/// RD score calculation for trellis
#[inline]
fn rd_score_trellis(lambda: u32, rate: i64, distortion: i64) -> i64 {
    rate * lambda as i64 + (RD_DISTO_MULT as i64) * distortion
}

/// Compute level cost using stored cost table (like libwebp's VP8LevelCost).
/// cost = VP8LevelFixedCosts[level] + table[min(level, MAX_VARIABLE_LEVEL)] + sign_bit
/// VP8LevelFixedCosts contains only magnitude encoding costs, sign bit is separate.
#[inline]
fn level_cost_with_table(costs: Option<&LevelCostArray>, level: i32) -> u32 {
    let abs_level = level.unsigned_abs() as usize;
    let fixed = VP8_LEVEL_FIXED_COSTS[abs_level.min(MAX_LEVEL)] as u32;
    let variable = match costs {
        Some(table) => table[abs_level.min(MAX_VARIABLE_LEVEL)] as u32,
        None => 0,
    };
    fixed + variable + if abs_level > 0 { 256 } else { 0 } // Sign bit for non-zero levels
}

/// Trellis-optimized quantization for a 4x4 block.
///
/// Uses dynamic programming to find optimal coefficient levels that minimize
/// the RD cost: distortion + lambda * rate.
///
/// This implementation follows libwebp's approach:
/// - Each state stores a pointer to the cost table for the *next* position
/// - Context is computed as min(level, 2) from the current level
/// - Predecessors' cost tables are used to compute transition costs
///
/// # Arguments
/// * `coeffs` - Input DCT coefficients (will be modified with reconstructed values)
/// * `out` - Output quantized levels
/// * `mtx` - Quantization matrix
/// * `lambda` - Rate-distortion trade-off parameter
/// * `first` - First coefficient to process (1 for I16_AC mode, 0 otherwise)
/// * `level_costs` - Probability-dependent level costs
/// * `ctype` - Token type for level cost lookup (0=Y2, 1=Y_AC, 2=Y_DC, 3=UV)
/// * `ctx0` - Initial context from neighboring blocks (0, 1, or 2)
///
/// # Returns
/// True if any non-zero coefficient was produced
pub fn trellis_quantize_block(
    coeffs: &mut [i32; 16],
    out: &mut [i32; 16],
    mtx: &VP8Matrix,
    lambda: u32,
    first: usize,
    level_costs: &LevelCosts,
    ctype: usize,
    ctx0: usize,
) -> bool {

    // Number of alternate levels to try: level-0 (MIN_DELTA=0) and level+1 (MAX_DELTA=1)
    const NUM_NODES: usize = 2; // [level, level+1]

    let mut nodes = [[TrellisNode::default(); NUM_NODES]; 16];
    let mut score_states = [[TrellisScoreState::default(); NUM_NODES]; 2];
    let mut ss_cur_idx = 0usize;
    let mut ss_prev_idx = 1usize;

    // Find last significant coefficient based on threshold
    let thresh = (mtx.q[1] as i64 * mtx.q[1] as i64 / 4) as i32;
    let mut last = first as i32 - 1;
    for n in (first..16).rev() {
        let j = VP8_ZIGZAG[n];
        let err = coeffs[j] * coeffs[j];
        if err > thresh {
            last = n as i32;
            break;
        }
    }
    // Extend by one to not lose too much
    if last < 15 {
        last += 1;
    }

    // Best path tracking: [last_pos, level_delta, prev_delta]
    let mut best_path = [-1i32; 3];

    // Initialize: compute skip score (all zeros = signal EOB immediately)
    // Skip means signaling EOB at the first position, not encoding a zero coefficient.
    let skip_cost = level_costs.get_skip_eob_cost(ctype, first, ctx0) as i64;
    let mut best_score = rd_score_trellis(lambda, skip_cost, 0);

    // Initialize source nodes with cost table for first position based on ctx0
    let initial_costs = level_costs.get_cost_table(ctype, first, ctx0);
    let init_rate = if ctx0 == 0 {
        level_costs.get_init_cost(ctype, first, ctx0) as i64
    } else {
        0
    };
    let init_score = rd_score_trellis(lambda, init_rate, 0);

    for delta in 0..NUM_NODES {
        score_states[ss_cur_idx][delta] = TrellisScoreState {
            score: init_score,
            costs: Some(initial_costs),
        };
    }

    // Traverse trellis
    for n in first..=last as usize {
        let j = VP8_ZIGZAG[n];
        let q = mtx.q[j] as i32;
        let iq = mtx.iq[j];
        let neutral_bias = quantization_bias(0x00);

        // Get sign from original coefficient
        let sign = coeffs[j] < 0;
        let abs_coeff = if sign { -coeffs[j] } else { coeffs[j] };
        let coeff_with_sharpen = abs_coeff + mtx.sharpen[j] as i32;

        // Base quantized level with neutral bias
        let level0 = quantdiv(coeff_with_sharpen as u32, iq, neutral_bias).min(MAX_LEVEL as i32);

        // Threshold level for pruning
        let thresh_bias = quantization_bias(0x80);
        let thresh_level =
            quantdiv(coeff_with_sharpen as u32, iq, thresh_bias).min(MAX_LEVEL as i32);

        // Swap score state indices
        std::mem::swap(&mut ss_cur_idx, &mut ss_prev_idx);

        // Test all alternate level values: level0 and level0+1
        for delta in 0..NUM_NODES {
            let node = &mut nodes[n][delta];
            let level = level0 + delta as i32;

            // Context for next position: min(level, 2)
            let ctx = (level as usize).min(2);

            // Store cost table for next position (based on context from this level)
            let next_costs = if n + 1 < 16 {
                Some(level_costs.get_cost_table(ctype, n + 1, ctx))
            } else {
                None
            };

            // Reset current score state
            score_states[ss_cur_idx][delta] = TrellisScoreState {
                score: MAX_COST,
                costs: next_costs,
            };

            // Skip invalid levels
            if level < 0 || level > thresh_level {
                continue;
            }

            // Compute distortion delta
            let new_error = coeff_with_sharpen - level * q;
            let orig_error_sq = (coeff_with_sharpen * coeff_with_sharpen) as i64;
            let new_error_sq = (new_error * new_error) as i64;
            let weight = VP8_WEIGHT_TRELLIS[j] as i64;
            let delta_distortion = weight * (new_error_sq - orig_error_sq);

            let base_score = rd_score_trellis(lambda, 0, delta_distortion);

            // Find best predecessor using stored cost tables
            let mut best_cur_score = MAX_COST;
            let mut best_prev = 0i8;

            for p in 0..NUM_NODES {
                // Use predecessor's stored cost table
                let cost = level_cost_with_table(score_states[ss_prev_idx][p].costs, level) as i64;
                let score = score_states[ss_prev_idx][p].score + rd_score_trellis(lambda, cost, 0);
                if score < best_cur_score {
                    best_cur_score = score;
                    best_prev = p as i8;
                }
            }

            best_cur_score += base_score;

            // Store in node
            node.sign = sign;
            node.level = level as i16;
            node.prev = best_prev;
            score_states[ss_cur_idx][delta].score = best_cur_score;

            // Check if this is the best terminal node
            if level != 0 && best_cur_score < best_score {
                // Add end-of-block cost: signaling "no more coefficients"
                // Uses the context resulting from this level
                let eob_cost = if n < 15 {
                    level_costs.get_eob_cost(ctype, n, ctx) as i64
                } else {
                    0
                };
                let terminal_score = best_cur_score + rd_score_trellis(lambda, eob_cost, 0);
                if terminal_score < best_score {
                    best_score = terminal_score;
                    best_path[0] = n as i32;
                    best_path[1] = delta as i32;
                    best_path[2] = best_prev as i32;
                }
            }
        }
    }

    // Clear output
    if first == 1 {
        // Preserve DC for I16_AC mode
        out[1..].fill(0);
        coeffs[1..].fill(0);
    } else {
        out.fill(0);
        coeffs.fill(0);
    }

    // No non-zero coefficients - skip block
    if best_path[0] == -1 {
        return false;
    }

    // Unwind best path
    let mut has_nz = false;
    let mut best_node_delta = best_path[1] as usize;
    let mut n = best_path[0] as usize;

    // Patch the prev for the terminal node
    nodes[n][best_node_delta].prev = best_path[2] as i8;

    loop {
        let node = &nodes[n][best_node_delta];
        let j = VP8_ZIGZAG[n];
        let level = if node.sign {
            -node.level as i32
        } else {
            node.level as i32
        };

        out[n] = level;
        has_nz |= level != 0;

        // Reconstruct coefficient for subsequent prediction
        coeffs[j] = level * mtx.q[j] as i32;

        if n == first {
            break;
        }
        best_node_delta = node.prev as usize;
        n -= 1;
    }

    has_nz
}

//------------------------------------------------------------------------------
// Coefficient cost estimation

/// Estimate the cost of encoding a 4x4 block of quantized coefficients.
///
/// This is a simplified approximation of libwebp's GetResidualCost.
/// It uses VP8_LEVEL_FIXED_COSTS which gives the probability-independent
/// part of the cost. The probability-dependent part is omitted for simplicity.
///
/// # Arguments
/// * `coeffs` - The 16 quantized coefficients in zig-zag order
/// * `first` - First coefficient to include (0 for DC+AC, 1 for AC only)
///
/// # Returns
/// Estimated bit cost in 1/256 bit units
#[inline]
pub fn estimate_residual_cost(coeffs: &[i32; 16], first: usize) -> u32 {
    let mut cost = 0u32;
    let mut last_nz = -1i32;

    // Find last non-zero coefficient
    for (i, &c) in coeffs.iter().enumerate().rev() {
        if c != 0 {
            last_nz = i as i32;
            break;
        }
    }

    // If no non-zero coefficients, just signal end of block
    if last_nz < first as i32 {
        // Cost of signaling "no coefficients" - approximately 1 bit
        return 256;
    }

    // Sum up costs for each coefficient
    for &coeff in coeffs.iter().take(last_nz as usize + 1).skip(first) {
        let level = coeff.unsigned_abs() as usize;
        if level > 0 {
            // Cost of the coefficient level
            let level_clamped = level.min(MAX_LEVEL);
            cost += u32::from(VP8_LEVEL_FIXED_COSTS[level_clamped]);
            // Add sign bit cost (1 bit = 256)
            cost += 256;
        } else {
            // Cost of zero (EOB not reached) - approximately 0.5 bits
            cost += 128;
        }
    }

    // Cost of end-of-block signal (approximately 0.5 bits)
    cost += 128;

    cost
}

/// Estimate coefficient cost for a 16x16 macroblock (16 4x4 blocks).
///
/// # Arguments
/// * `blocks` - Array of 16 quantized coefficient blocks
/// * `has_dc` - Whether to include DC coefficients (false for I16 where DC is separate)
#[inline]
pub fn estimate_luma16_cost(blocks: &[[i32; 16]; 16], has_dc: bool) -> u32 {
    let first = if has_dc { 0 } else { 1 };
    blocks
        .iter()
        .map(|block| estimate_residual_cost(block, first))
        .sum()
}

/// Estimate coefficient cost for DC block in I16 mode.
#[inline]
pub fn estimate_dc16_cost(dc_coeffs: &[i32; 16]) -> u32 {
    estimate_residual_cost(dc_coeffs, 0)
}

//------------------------------------------------------------------------------
// RD score calculation

/// Calculate RD score for mode selection.
///
/// Formula: score = SSE * RD_DISTO_MULT + mode_cost * lambda
///
/// Lower score = better trade-off between quality and bits.
#[inline]
pub fn rd_score(sse: u32, mode_cost: u16, lambda: u32) -> u64 {
    let distortion = u64::from(sse) * u64::from(RD_DISTO_MULT);
    let rate = u64::from(mode_cost) * u64::from(lambda);
    distortion + rate
}

/// Calculate full RD score including coefficient costs.
///
/// Formula: score = SSE * RD_DISTO_MULT + (mode_cost + coeff_cost) * lambda
///
/// # Arguments
/// * `sse` - Sum of squared errors (distortion)
/// * `mode_cost` - Mode signaling cost in 1/256 bits
/// * `coeff_cost` - Coefficient encoding cost in 1/256 bits
/// * `lambda` - Rate-distortion trade-off parameter
#[inline]
pub fn rd_score_with_coeffs(sse: u32, mode_cost: u16, coeff_cost: u32, lambda: u32) -> u64 {
    let distortion = u64::from(sse) * u64::from(RD_DISTO_MULT);
    let rate = (u64::from(mode_cost) + u64::from(coeff_cost)) * u64::from(lambda);
    distortion + rate
}

/// Calculate full RD score as used by libwebp's PickBestIntra16.
///
/// Formula: score = (R + H) * lambda + RD_DISTO_MULT * (D + SD)
///
/// Where:
/// - R = coefficient encoding cost (rate)
/// - H = mode header cost
/// - D = SSE distortion on reconstructed block
/// - SD = spectral distortion (TDisto)
///
/// # Arguments
/// * `sse` - Sum of squared errors (D)
/// * `spectral_disto` - Spectral distortion from TDisto (SD), already scaled by tlambda
/// * `mode_cost` - Mode signaling cost (H)
/// * `coeff_cost` - Coefficient encoding cost (R)
/// * `lambda` - Rate-distortion trade-off parameter
#[inline]
pub fn rd_score_full(
    sse: u32,
    spectral_disto: i32,
    mode_cost: u16,
    coeff_cost: u32,
    lambda: u32,
) -> i64 {
    let rate = (i64::from(mode_cost) + i64::from(coeff_cost)) * i64::from(lambda);
    let distortion = i64::from(RD_DISTO_MULT) * (i64::from(sse) + i64::from(spectral_disto));
    rate + distortion
}

/// Get context-dependent Intra4 mode cost.
///
/// # Arguments
/// * `top` - The mode of the block above (0-9)
/// * `left` - The mode of the block to the left (0-9)
/// * `mode` - The mode to get the cost for (0-9)
#[inline]
pub fn get_i4_mode_cost(top: usize, left: usize, mode: usize) -> u16 {
    VP8_FIXED_COSTS_I4[top][left][mode]
}

//------------------------------------------------------------------------------
// Token Statistics for Adaptive Probabilities
//
// Ported from libwebp src/enc/cost_enc.h and src/enc/frame_enc.c
// This enables two-pass encoding with optimal probability updates.

/// Number of coefficient types (DCT types: 0=i16-DC, 1=i16-AC, 2=chroma, 3=i4)
pub const NUM_TYPES: usize = 4;
/// Number of bands for coefficient encoding
pub const NUM_BANDS: usize = 8;
/// Number of contexts (0=zero, 1=one, 2=more)
pub const NUM_CTX: usize = 3;
/// Number of probabilities per context node
pub const NUM_PROBAS: usize = 11;

/// Token statistics for computing optimal probabilities.
/// Format: upper 16 bits = total count, lower 16 bits = count of 1s.
/// Ported from libwebp's proba_t type.
#[derive(Clone, Default)]
pub struct ProbaStats {
    /// Statistics array: [type][band][context][proba_node]
    pub stats: [[[[u32; NUM_PROBAS]; NUM_CTX]; NUM_BANDS]; NUM_TYPES],
}

impl ProbaStats {
    /// Create new empty statistics
    pub fn new() -> Self {
        Self::default()
    }

    /// Reset all statistics to zero
    pub fn reset(&mut self) {
        for t in self.stats.iter_mut() {
            for b in t.iter_mut() {
                for c in b.iter_mut() {
                    for p in c.iter_mut() {
                        *p = 0;
                    }
                }
            }
        }
    }

    /// Record a bit value for a specific probability node.
    /// Ported from libwebp's VP8RecordStats.
    #[inline]
    pub fn record(&mut self, t: usize, b: usize, c: usize, p: usize, bit: bool) {
        let stats = &mut self.stats[t][b][c][p];
        // Check for overflow (at 0xfffe0000)
        if *stats >= 0xfffe_0000 {
            // Divide stats by 2 to prevent overflow
            *stats = ((*stats + 1) >> 1) & 0x7fff_7fff;
        }
        // Record: lower 16 bits = count of 1s, upper 16 bits = total count
        *stats += 0x0001_0000 + if bit { 1 } else { 0 };
    }

    /// Get the optimal probability for a node based on accumulated statistics.
    /// Returns 255 - (nb * 255 / total) where nb = count of 1s.
    pub fn calc_proba(&self, t: usize, b: usize, c: usize, p: usize) -> u8 {
        let stats = self.stats[t][b][c][p];
        let nb = (stats & 0xffff) as u32; // count of 1s
        let total = (stats >> 16) as u32; // total count
        if total == 0 {
            return 255;
        }
        let proba = 255 - (nb * 255 / total);
        proba as u8
    }

    /// Calculate the cost of updating vs keeping old probability.
    /// Returns (should_update, new_prob, bit_savings).
    pub fn should_update(
        &self,
        t: usize,
        b: usize,
        c: usize,
        p: usize,
        old_proba: u8,
        update_proba: u8,
    ) -> (bool, u8, i32) {
        let stats = self.stats[t][b][c][p];
        let nb = (stats & 0xffff) as i32; // count of 1s
        let total = (stats >> 16) as i32; // total count

        if total == 0 {
            return (false, old_proba, 0);
        }

        let new_p = self.calc_proba(t, b, c, p);

        // Cost with old probability
        let old_cost = branch_cost(nb, total, old_proba) + vp8_bit_cost(false, update_proba) as i32;

        // Cost with new probability (includes signaling cost)
        let new_cost =
            branch_cost(nb, total, new_p) + vp8_bit_cost(true, update_proba) as i32 + 8 * 256; // 8 bits to signal new probability value

        let savings = old_cost - new_cost;
        (savings > 0, new_p, savings)
    }
}

/// Calculate the branch cost for a given count distribution and probability.
/// Cost = nb * cost(1|p) + (total - nb) * cost(0|p)
#[inline]
fn branch_cost(nb: i32, total: i32, proba: u8) -> i32 {
    let cost_1 = VP8_ENTROPY_COST[255 - proba as usize] as i32;
    let cost_0 = VP8_ENTROPY_COST[proba as usize] as i32;
    nb * cost_1 + (total - nb) * cost_0
}

/// Token type for coefficient encoding
#[derive(Clone, Copy, Debug, PartialEq, Eq)]
pub enum TokenType {
    /// I16 DC coefficients (Y2/WHT)
    I16DC = 0,
    /// I16 AC coefficients (Y1 blocks with DC=0)
    I16AC = 1,
    /// Chroma (UV) coefficients
    Chroma = 2,
    /// I4 coefficients
    I4 = 3,
}

/// Record coefficient tokens for probability statistics.
/// Structure matches the encoder's skip_eob pattern exactly:
/// - For each coefficient, check node 0 (EOB) if skip_eob=false
/// - Check node 1 (zero/non-zero) for all coefficients
/// - Set skip_eob=true after zeros (can skip EOB check after a zero)
/// - At end, record EOB at node 0 if there are trailing positions
///
/// # Arguments
/// * `coeffs` - Quantized coefficients in zigzag order (16 values)
/// * `token_type` - Type of coefficients (I16DC, I16AC, Chroma, I4)
/// * `first` - First coefficient to process (0 or 1)
/// * `ctx` - Initial context (0, 1, or 2)
/// * `stats` - Statistics accumulator
pub fn record_coeffs(
    coeffs: &[i32],
    token_type: TokenType,
    first: usize,
    ctx: usize,
    stats: &mut ProbaStats,
) {
    let t = token_type as usize;
    let mut n = first;
    let mut context = ctx;

    // Find last non-zero coefficient (end_of_block_index - 1)
    let last = coeffs
        .iter()
        .rposition(|&c| c != 0)
        .map(|i| i as i32)
        .unwrap_or(-1);

    let end_of_block = if last >= 0 { (last + 1) as usize } else { 0 };

    // If no non-zero coefficients, record EOB immediately
    if end_of_block <= first {
        let band = VP8_ENC_BANDS[first] as usize;
        stats.record(t, band, context, 0, false); // EOB at node 0
        return;
    }

    // Track skip_eob like the encoder does
    let mut skip_eob = false;

    // Process coefficients up to end_of_block (last non-zero + 1)
    while n < end_of_block {
        let band = VP8_ENC_BANDS[n] as usize;
        let v = coeffs[n].unsigned_abs();
        n += 1;

        // Record at node 0 (EOB check) if not skipping
        if !skip_eob {
            stats.record(t, band, context, 0, true); // not EOB
        }

        if v == 0 {
            // Zero coefficient: record 0 at node 1, set skip_eob for next
            stats.record(t, band, context, 1, false);
            skip_eob = true;
            context = 0;
            continue;
        }

        // Non-zero coefficient: record 1 at node 1
        stats.record(t, band, context, 1, true);

        // Record value magnitude bits
        if v == 1 {
            stats.record(t, band, context, 2, false);
            context = 1;
        } else {
            stats.record(t, band, context, 2, true);

            // Clamp v to MAX_VARIABLE_LEVEL for statistics
            let v = v.min(MAX_VARIABLE_LEVEL as u32);

            if v <= 4 {
                stats.record(t, band, context, 3, false);
                if v == 2 {
                    stats.record(t, band, context, 4, false);
                } else {
                    stats.record(t, band, context, 4, true);
                    stats.record(t, band, context, 5, v == 4);
                }
            } else if v <= 10 {
                stats.record(t, band, context, 3, true);
                stats.record(t, band, context, 6, false);
                stats.record(t, band, context, 7, v > 6);
            } else {
                stats.record(t, band, context, 3, true);
                stats.record(t, band, context, 6, true);

                if v < 3 + (8 << 2) {
                    stats.record(t, band, context, 8, false);
                    stats.record(t, band, context, 9, v >= 3 + (8 << 1));
                } else {
                    stats.record(t, band, context, 8, true);
                    stats.record(t, band, context, 10, v >= 3 + (8 << 3));
                }
            }

            context = 2;
        }

        // After non-zero, the encoder does NOT reset skip_eob to false.
        // It leaves it unchanged. So if skip_eob was true (from a previous zero),
        // it stays true even after this non-zero. Do NOT reset it here!
    }

    // Record trailing EOB if we didn't reach position 16
    if n < 16 {
        let band = VP8_ENC_BANDS[n] as usize;
        stats.record(t, band, context, 0, false); // EOB
    }
}

//------------------------------------------------------------------------------
// Level cost tables for accurate coefficient cost estimation
//
// Ported from libwebp src/enc/cost_enc.c
//
// The key insight is that coefficient costs depend on the probability context.
// VP8CalculateLevelCosts precomputes cost tables indexed by [type][band][ctx][level].
// Then remapped_costs provides direct access by coefficient position: [type][n][ctx].

use crate::vp8_common::TokenProbTables;

/// Type alias for level cost array: cost for each level 0..=MAX_VARIABLE_LEVEL
pub type LevelCostArray = [u16; MAX_VARIABLE_LEVEL + 1];

/// Level costs indexed by [type][band][context]
/// Each entry is an array of costs for levels 0..=MAX_VARIABLE_LEVEL
pub type LevelCostTables = [[[LevelCostArray; NUM_CTX]; NUM_BANDS]; NUM_TYPES];

/// Remapped costs indexed by [type][position][context]
/// Maps coefficient position (0..16) directly to its band's level_cost.
/// This avoids the indirection through VP8_ENC_BANDS during cost calculation.
pub type RemappedCosts = [[usize; NUM_CTX]; 16];

/// Calculate the variable-length cost for encoding a level >= 1.
/// Uses the VP8_LEVEL_CODES table to determine which probability nodes to use.
/// Ported from libwebp's VariableLevelCost.
fn variable_level_cost(level: usize, probas: &[u8; NUM_PROBAS]) -> u16 {
    if level == 0 {
        return 0;
    }
    let idx = level.min(MAX_VARIABLE_LEVEL) - 1;
    let pattern = VP8_LEVEL_CODES[idx][0];
    let bits = VP8_LEVEL_CODES[idx][1];

    let mut cost = 0u16;
    let mut p = pattern;
    let mut b = bits;
    let mut i = 2; // Start at proba index 2

    while p != 0 {
        if (p & 1) != 0 {
            cost += vp8_bit_cost((b & 1) != 0, probas[i]);
        }
        b >>= 1;
        p >>= 1;
        i += 1;
    }
    cost
}

/// Level cost tables holder with precomputed costs and remapping.
/// Ported from libwebp's VP8EncProba (level_cost and remapped_costs fields).
#[derive(Clone)]
pub struct LevelCosts {
    /// Level costs indexed by [type][band][ctx][level]
    pub level_cost: LevelCostTables,
    /// Remapped indices: [type][position] -> band index for each type
    /// Usage: level_cost[type][remapped[type][n]][ctx][level]
    remapped: [RemappedCosts; NUM_TYPES],
    /// EOB (end-of-block) costs indexed by [type][band][ctx]
    /// This is the cost of signaling "no more coefficients"
    eob_cost: [[[u16; NUM_CTX]; NUM_BANDS]; NUM_TYPES],
    /// Init (has-coefficients) costs indexed by [type][band][ctx]
    /// This is the cost of signaling "block has coefficients"
    /// Used for initializing trellis at ctx0=0
    init_cost: [[[u16; NUM_CTX]; NUM_BANDS]; NUM_TYPES],
    /// Whether the tables are dirty and need recalculation
    dirty: bool,
}

impl Default for LevelCosts {
    fn default() -> Self {
        Self::new()
    }
}

impl LevelCosts {
    /// Create new level cost tables
    pub fn new() -> Self {
        Self {
            level_cost: [[[[0u16; MAX_VARIABLE_LEVEL + 1]; NUM_CTX]; NUM_BANDS]; NUM_TYPES],
            remapped: [[[0usize; NUM_CTX]; 16]; NUM_TYPES],
            eob_cost: [[[0u16; NUM_CTX]; NUM_BANDS]; NUM_TYPES],
            init_cost: [[[0u16; NUM_CTX]; NUM_BANDS]; NUM_TYPES],
            dirty: true,
        }
    }

    /// Mark tables as dirty (need recalculation)
    pub fn mark_dirty(&mut self) {
        self.dirty = true;
    }

    /// Check if tables need recalculation
    pub fn is_dirty(&self) -> bool {
        self.dirty
    }

    /// Calculate level costs from probability tables.
    /// Ported from libwebp's VP8CalculateLevelCosts.
    pub fn calculate(&mut self, probs: &TokenProbTables) {
        if !self.dirty {
            return;
        }

        for ctype in 0..NUM_TYPES {
            for band in 0..NUM_BANDS {
                for ctx in 0..NUM_CTX {
                    let p = &probs[ctype][band][ctx];

                    // cost0 is the cost of signaling "no more coefficients" at context > 0
                    // For ctx == 0, this cost is handled separately
                    let cost0 = if ctx > 0 {
                        vp8_bit_cost(true, p[0])
                    } else {
                        0
                    };

                    // cost_base is cost of signaling "coefficient present" + cost0
                    let cost_base = vp8_bit_cost(true, p[1]) + cost0;

                    // Level 0: just signal "no coefficient"
                    self.level_cost[ctype][band][ctx][0] = vp8_bit_cost(false, p[1]) + cost0;

                    // Levels 1..=MAX_VARIABLE_LEVEL
                    for v in 1..=MAX_VARIABLE_LEVEL {
                        self.level_cost[ctype][band][ctx][v] =
                            cost_base + variable_level_cost(v, p);
                    }

                    // EOB cost: signaling "no more coefficients" after this position
                    // This is the cost of taking the EOB branch in the coefficient tree
                    self.eob_cost[ctype][band][ctx] = vp8_bit_cost(false, p[0]);

                    // Init cost: signaling "block has coefficients" at this position
                    // Used for initializing trellis at ctx0=0
                    self.init_cost[ctype][band][ctx] = vp8_bit_cost(true, p[0]);
                }
            }

            // Build remapped indices for direct position-based lookup
            for n in 0..16 {
                let band = VP8_ENC_BANDS[n] as usize;
                for ctx in 0..NUM_CTX {
                    self.remapped[ctype][n][ctx] = band;
                }
            }
        }

        self.dirty = false;
    }

    /// Get level cost for a specific coefficient position.
    /// Combines fixed cost from VP8_LEVEL_FIXED_COSTS and variable cost from tables.
    #[inline]
    pub fn get_level_cost(&self, ctype: usize, position: usize, ctx: usize, level: usize) -> u32 {
        let fixed = VP8_LEVEL_FIXED_COSTS[level.min(MAX_LEVEL)] as u32;
        let band = self.remapped[ctype][position][ctx];
        let variable = self.level_cost[ctype][band][ctx][level.min(MAX_VARIABLE_LEVEL)] as u32;
        fixed + variable
    }

    /// Get the cost table for a specific type, position, and context.
    #[inline]
    pub fn get_cost_table(&self, ctype: usize, position: usize, ctx: usize) -> &LevelCostArray {
        let band = self.remapped[ctype][position][ctx];
        &self.level_cost[ctype][band][ctx]
    }

    /// Get the EOB (end-of-block) cost for terminating after position n.
    /// This is the cost of signaling "no more coefficients" at position n+1.
    /// The context should be based on the level at position n (ctx = min(level, 2)).
    #[inline]
    pub fn get_eob_cost(&self, ctype: usize, position: usize, ctx: usize) -> u16 {
        // EOB is signaled at position n+1, so use band for n+1
        let next_pos = (position + 1).min(15);
        let band = VP8_ENC_BANDS[next_pos] as usize;
        self.eob_cost[ctype][band][ctx]
    }

    /// Get the EOB cost for signaling "no coefficients at all" at position first.
    /// Used for skip (all-zero block) calculation.
    #[inline]
    pub fn get_skip_eob_cost(&self, ctype: usize, first: usize, ctx: usize) -> u16 {
        let band = VP8_ENC_BANDS[first] as usize;
        self.eob_cost[ctype][band][ctx]
    }

    /// Get the init cost for signaling "block has coefficients" at position first.
    /// Used for initializing trellis at ctx0=0.
    #[inline]
    pub fn get_init_cost(&self, ctype: usize, first: usize, ctx: usize) -> u16 {
        let band = VP8_ENC_BANDS[first] as usize;
        self.init_cost[ctype][band][ctx]
    }
}

/// Residual coefficients for cost calculation.
/// Ported from libwebp's VP8Residual.
pub struct Residual<'a> {
    /// First coefficient to consider (0 or 1)
    pub first: usize,
    /// Last non-zero coefficient index (-1 if all zero)
    pub last: i32,
    /// Coefficient array
    pub coeffs: &'a [i32; 16],
    /// Coefficient type (0=I16DC, 1=I16AC, 2=Chroma, 3=I4)
    pub coeff_type: usize,
}

impl<'a> Residual<'a> {
    /// Create a new residual from coefficients.
    /// Automatically finds the last non-zero coefficient.
    pub fn new(coeffs: &'a [i32; 16], coeff_type: usize, first: usize) -> Self {
        let last = coeffs
            .iter()
            .rposition(|&c| c != 0)
            .map(|i| i as i32)
            .unwrap_or(-1);

        Self {
            first,
            last,
            coeffs,
            coeff_type,
        }
    }
}

/// Calculate the cost of encoding a residual block using probability-based costs.
/// Ported from libwebp's GetResidualCost_C.
///
/// # Arguments
/// * `ctx0` - Initial context (0, 1, or 2)
/// * `res` - Residual coefficients
/// * `costs` - Precomputed level cost tables
/// * `probs` - Probability tables (for last coefficient EOB cost)
///
/// # Returns
/// Cost in 1/256 bit units
pub fn get_residual_cost(
    ctx0: usize,
    res: &Residual,
    costs: &LevelCosts,
    probs: &TokenProbTables,
) -> u32 {
    let ctype = res.coeff_type;
    let mut n = res.first;

    // Get probability p0 for the first coefficient
    // Note: for n=0 or n=1, band = n (VP8_ENC_BANDS[0]=0, VP8_ENC_BANDS[1]=1)
    let band = VP8_ENC_BANDS[n] as usize;
    let p0 = probs[ctype][band][ctx0][0];

    // Current context - starts at ctx0, updated after each coefficient
    let mut ctx = ctx0;

    // bit_cost(1, p0) is already incorporated in the cost tables, but only if ctx != 0.
    // For ctx0 == 0, we need to add it explicitly.
    let mut cost = if ctx0 == 0 {
        vp8_bit_cost(true, p0) as u32
    } else {
        0
    };

    // If no non-zero coefficients, just return EOB cost
    if res.last < 0 {
        return vp8_bit_cost(false, p0) as u32;
    }

    // Process coefficients from first to last-1
    // Context updates: ctx for position n+1 depends on coefficient value at position n
    while (n as i32) < res.last {
        let v = res.coeffs[n].abs() as usize;

        // Add cost using current context
        cost += costs.get_level_cost(ctype, n, ctx, v);

        // Update context for next position based on current value
        ctx = if v >= 2 { 2 } else { v };

        n += 1;
    }

    // Last coefficient is always non-zero
    {
        let v = res.coeffs[n].abs() as usize;
        debug_assert!(v != 0, "Last coefficient should be non-zero");

        // Add cost using current context
        cost += costs.get_level_cost(ctype, n, ctx, v);

        // Add EOB cost for the position after the last coefficient
        if n < 15 {
            let next_band = VP8_ENC_BANDS[n + 1] as usize;
            let next_ctx = if v == 1 { 1 } else { 2 };
            let last_p0 = probs[ctype][next_band][next_ctx][0];
            cost += vp8_bit_cost(false, last_p0) as u32;
        }
    }

    cost
}

/// Calculate the cost of encoding a 4x4 luma block (I4 mode).
/// Ported from libwebp's VP8GetCostLuma4.
///
/// # Arguments
/// * `levels` - Quantized coefficients in zigzag order
/// * `top_nz` - Whether the above block had non-zero coefficients
/// * `left_nz` - Whether the left block had non-zero coefficients
/// * `costs` - Precomputed level cost tables
/// * `probs` - Probability tables
///
/// # Returns
/// (cost, has_nonzero) - Cost in 1/256 bits and whether this block has non-zero coeffs
pub fn get_cost_luma4(
    levels: &[i32; 16],
    top_nz: bool,
    left_nz: bool,
    costs: &LevelCosts,
    probs: &TokenProbTables,
) -> (u32, bool) {
    // Initial context is sum of top and left non-zero flags (0, 1, or 2)
    let ctx = (top_nz as usize) + (left_nz as usize);

    // Create residual for I4 type (type 3), starting at position 0
    let res = Residual::new(levels, 3, 0);
    let has_nz = res.last >= 0;

    let cost = get_residual_cost(ctx, &res, costs, probs);

    (cost, has_nz)
}

/// Calculate the cost of encoding all 16 luma blocks in I16 mode.
/// Includes DC block (Y2) and 16 AC blocks (Y1).
///
/// # Arguments
/// * `dc_levels` - DC coefficients from WHT (16 values)
/// * `ac_levels` - AC coefficients for each 4x4 block (16 blocks × 16 coeffs)
/// * `costs` - Precomputed level cost tables
/// * `probs` - Probability tables
///
/// # Returns
/// Total cost in 1/256 bits
pub fn get_cost_luma16(
    dc_levels: &[i32; 16],
    ac_levels: &[[i32; 16]; 16],
    costs: &LevelCosts,
    probs: &TokenProbTables,
) -> u32 {
    let mut total_cost = 0u32;

    // DC block (type 1 = I16DC, also known as Y2)
    // Context is typically from neighboring DC blocks, but for simplicity use 0
    let dc_res = Residual::new(dc_levels, 1, 0);
    total_cost += get_residual_cost(0, &dc_res, costs, probs);

    // AC blocks (type 0 = I16AC, skipping DC coefficient which is in Y2)
    for ac in ac_levels.iter() {
        let ac_res = Residual::new(ac, 0, 1); // Start at position 1 (skip DC)
        total_cost += get_residual_cost(0, &ac_res, costs, probs);
    }

    total_cost
}

/// Compute accurate coefficient cost for UV blocks using probability-dependent tables.
///
/// Port of libwebp's VP8GetCostUV.
///
/// # Arguments
/// * `uv_levels` - 8 blocks of quantized coefficients (4 U blocks + 4 V blocks)
/// * `costs` - Precomputed level cost tables
/// * `probs` - Probability tables
///
/// # Returns
/// Total cost in 1/256 bits
pub fn get_cost_uv(
    uv_levels: &[[i32; 16]; 8],
    costs: &LevelCosts,
    probs: &TokenProbTables,
) -> u32 {
    let mut total_cost = 0u32;

    // UV blocks use coeff_type=2 (TYPE_CHROMA_A)
    // All coefficients including DC (first=0)
    for block in uv_levels.iter() {
        let res = Residual::new(block, 2, 0); // ctype=2 for UV, first=0 (include DC)
        total_cost += get_residual_cost(0, &res, costs, probs);
    }

    total_cost
}

//------------------------------------------------------------------------------
// Segment-based quantization
//
// Ported from libwebp src/enc/analysis_enc.c
// Allows different quantization levels for different image regions.
//
// The analysis pass computes "alpha" (compressibility) for each macroblock
// using DCT histogram analysis, then uses k-means clustering to assign
// segments for per-region quantization.

/// Maximum alpha value for macroblock complexity
pub const MAX_ALPHA: u8 = 255;

/// Alpha scale factor (from libwebp: ALPHA_SCALE = 2 * MAX_ALPHA = 510)
const ALPHA_SCALE: u32 = 2 * MAX_ALPHA as u32;

/// Maximum coefficient threshold for histogram binning (from libwebp)
const MAX_COEFF_THRESH: usize = 31;

/// Number of k-means iterations for segment assignment
const MAX_ITERS_K_MEANS: usize = 6;

/// Number of segments
pub const NUM_SEGMENTS: usize = 4;

/// Number of intra16 modes to test during analysis (DC=0, TM=1)
const MAX_INTRA16_MODE: usize = 2;

/// Number of UV modes to test during analysis (DC=0, TM=1)
const MAX_UV_MODE: usize = 2;

/// Bytes per stride in libwebp's work buffers
const BPS: usize = 32;

/// Offset to Y plane in work buffer
const Y_OFF_ENC: usize = 0;

/// Offset to U plane in work buffer
const U_OFF_ENC: usize = 16;

/// Offset to V plane in work buffer
const V_OFF_ENC: usize = 24;

/// Offsets to each 4x4 block within a BPS-strided buffer
/// Ported from libwebp's VP8DspScan
/// The 0 * BPS expressions are intentional to match libwebp's pattern
#[allow(clippy::erasing_op, clippy::identity_op)]
const VP8_DSP_SCAN: [usize; 24] = [
    // Luma (16 blocks)
    0 + 0 * BPS,
    4 + 0 * BPS,
    8 + 0 * BPS,
    12 + 0 * BPS,
    0 + 4 * BPS,
    4 + 4 * BPS,
    8 + 4 * BPS,
    12 + 4 * BPS,
    0 + 8 * BPS,
    4 + 8 * BPS,
    8 + 8 * BPS,
    12 + 8 * BPS,
    0 + 12 * BPS,
    4 + 12 * BPS,
    8 + 12 * BPS,
    12 + 12 * BPS,
    // U (4 blocks)
    0 + 0 * BPS,
    4 + 0 * BPS,
    0 + 4 * BPS,
    4 + 4 * BPS,
    // V (4 blocks, offset by 8 from U)
    8 + 0 * BPS,
    12 + 0 * BPS,
    8 + 4 * BPS,
    12 + 4 * BPS,
];

/// Mode offsets for I16 predictions in yuv_p buffer
/// Ported from libwebp's VP8I16ModeOffsets
const I16DC16: usize = 0;
const I16TM16: usize = I16DC16 + 16;
const I16VE16: usize = 1 * 16 * BPS;
const I16HE16: usize = I16VE16 + 16;

const VP8_I16_MODE_OFFSETS: [usize; 4] = [I16DC16, I16TM16, I16VE16, I16HE16];

/// Mode offsets for chroma predictions in yuv_p buffer
/// Ported from libwebp's VP8UVModeOffsets
const C8DC8: usize = 2 * 16 * BPS;
const C8TM8: usize = C8DC8 + 16;
const C8VE8: usize = 2 * 16 * BPS + 8 * BPS;
const C8HE8: usize = C8VE8 + 16;

const VP8_UV_MODE_OFFSETS: [usize; 4] = [C8DC8, C8TM8, C8VE8, C8HE8];

/// Size of prediction buffer (I16 + Chroma + I4 preds)
const PRED_SIZE_ENC: usize = 32 * BPS + 16 * BPS + 8 * BPS;

/// Size of YUV work buffer
const YUV_SIZE_ENC: usize = BPS * 16;

/// DCT histogram result for alpha calculation
/// Ported from libwebp's VP8Histogram struct
#[derive(Default, Clone, Copy)]
pub struct DctHistogram {
    /// Maximum count in any histogram bin
    pub max_value: u32,
    /// Highest bin index with non-zero count
    pub last_non_zero: usize,
}

impl DctHistogram {
    /// Initialize histogram with default values (from libwebp's InitHistogram)
    pub fn new() -> Self {
        Self {
            max_value: 0,
            last_non_zero: 1,
        }
    }

    /// Compute histogram data from a distribution array
    /// Ported from libwebp's VP8SetHistogramData
    pub fn from_distribution(distribution: &[u32; MAX_COEFF_THRESH + 1]) -> Self {
        let mut max_value: u32 = 0;
        let mut last_non_zero: usize = 1;

        for (k, &count) in distribution.iter().enumerate() {
            if count > 0 {
                if count > max_value {
                    max_value = count;
                }
                last_non_zero = k;
            }
        }

        Self {
            max_value,
            last_non_zero,
        }
    }

    /// Get alpha value from histogram
    /// Ported from libwebp's GetAlpha
    pub fn get_alpha(&self) -> i32 {
        if self.max_value > 1 {
            (ALPHA_SCALE * self.last_non_zero as u32 / self.max_value) as i32
        } else {
            0
        }
    }
}

/// Forward DCT on a 4x4 block (difference between source and prediction)
/// Ported from libwebp's VP8FTransform (FTransform_C)
fn forward_dct_4x4(src: &[u8], pred: &[u8], src_stride: usize, pred_stride: usize) -> [i16; 16] {
    let mut tmp = [0i32; 16];
    let mut out = [0i16; 16];

    // Horizontal pass: compute differences and first butterfly
    for i in 0..4 {
        let src_row = i * src_stride;
        let pred_row = i * pred_stride;

        let d0 = i32::from(src[src_row]) - i32::from(pred[pred_row]);
        let d1 = i32::from(src[src_row + 1]) - i32::from(pred[pred_row + 1]);
        let d2 = i32::from(src[src_row + 2]) - i32::from(pred[pred_row + 2]);
        let d3 = i32::from(src[src_row + 3]) - i32::from(pred[pred_row + 3]);

        let a0 = d0 + d3;
        let a1 = d1 + d2;
        let a2 = d1 - d2;
        let a3 = d0 - d3;

        tmp[0 + i * 4] = (a0 + a1) * 8;
        tmp[2 + i * 4] = (a0 - a1) * 8;
        tmp[1 + i * 4] = (a2 * 2217 + a3 * 5352 + 1812) >> 9;
        tmp[3 + i * 4] = (a3 * 2217 - a2 * 5352 + 937) >> 9;
    }

    // Vertical pass
    for i in 0..4 {
        let a0 = tmp[0 + i] + tmp[12 + i];
        let a1 = tmp[4 + i] + tmp[8 + i];
        let a2 = tmp[4 + i] - tmp[8 + i];
        let a3 = tmp[0 + i] - tmp[12 + i];

        out[0 + i] = ((a0 + a1 + 7) >> 4) as i16;
        out[8 + i] = ((a0 - a1 + 7) >> 4) as i16;
        out[4 + i] = (((a2 * 2217 + a3 * 5352 + 12000) >> 16) + if a3 != 0 { 1 } else { 0 }) as i16;
        out[12 + i] = ((a3 * 2217 - a2 * 5352 + 51000) >> 16) as i16;
    }

    out
}

/// Collect DCT histogram for a range of 4x4 blocks
/// Ported from libwebp's CollectHistogram_C / VP8CollectHistogram
///
/// # Arguments
/// * `src` - Source pixels (BPS stride)
/// * `pred` - Prediction pixels (BPS stride)
/// * `start_block` - First block index (in VP8DspScan)
/// * `end_block` - One past last block index
pub fn collect_histogram_bps(
    src: &[u8],
    pred: &[u8],
    start_block: usize,
    end_block: usize,
) -> DctHistogram {
    let mut distribution = [0u32; MAX_COEFF_THRESH + 1];

    for j in start_block..end_block {
        let src_off = VP8_DSP_SCAN[j];
        let pred_off = VP8_DSP_SCAN[j];

        let dct_out = forward_dct_4x4(&src[src_off..], &pred[pred_off..], BPS, BPS);

        for coeff in dct_out.iter() {
            let v = (coeff.unsigned_abs() >> 3) as usize;
            let clipped = v.min(MAX_COEFF_THRESH);
            distribution[clipped] += 1;
        }
    }

    DctHistogram::from_distribution(&distribution)
}

/// Finalize alpha value by inverting and clipping
/// Ported from libwebp's FinalAlphaValue
#[inline]
fn final_alpha_value(alpha: i32) -> u8 {
    let alpha = MAX_ALPHA as i32 - alpha;
    alpha.clamp(0, MAX_ALPHA as i32) as u8
}

//------------------------------------------------------------------------------
// Prediction functions for analysis
// Ported from libwebp's VP8EncPredLuma16 and VP8EncPredChroma8

/// Generate DC prediction for 16x16 luma block into BPS-strided buffer
/// Ported from libwebp's DCMode (size=16, round=16, shift=5)
fn pred_luma16_dc(dst: &mut [u8], left: Option<&[u8]>, top: Option<&[u8]>) {
    let dc_val = match (top, left) {
        (Some(top), Some(left)) => {
            // Both borders: sum all 32 samples
            let mut dc: u32 = 0;
            for i in 0..16 {
                dc += u32::from(top[i]);
                dc += u32::from(left[i]);
            }
            ((dc + 16) >> 5) as u8
        }
        (Some(top), None) => {
            // Top only: sum 16 samples, double, then shift by 5
            let mut dc: u32 = 0;
            for i in 0..16 {
                dc += u32::from(top[i]);
            }
            dc += dc; // Double
            ((dc + 16) >> 5) as u8
        }
        (None, Some(left)) => {
            // Left only: sum 16 samples, double, then shift by 5
            let mut dc: u32 = 0;
            for i in 0..16 {
                dc += u32::from(left[i]);
            }
            dc += dc; // Double
            ((dc + 16) >> 5) as u8
        }
        (None, None) => {
            // No borders: use 128
            0x80u8
        }
    };

    // Fill 16x16 block
    for y in 0..16 {
        for x in 0..16 {
            dst[y * BPS + x] = dc_val;
        }
    }
}

/// Fill a block with a constant value (BPS stride)
fn fill_block(dst: &mut [u8], value: u8, size: usize) {
    for y in 0..size {
        for x in 0..size {
            dst[y * BPS + x] = value;
        }
    }
}

/// Vertical prediction: copy top row to all rows
fn vertical_pred(dst: &mut [u8], top: Option<&[u8]>, size: usize) {
    if let Some(top) = top {
        for y in 0..size {
            for x in 0..size {
                dst[y * BPS + x] = top[x];
            }
        }
    } else {
        fill_block(dst, 127, size);
    }
}

/// Horizontal prediction: copy left column to all columns
fn horizontal_pred(dst: &mut [u8], left: Option<&[u8]>, size: usize) {
    if let Some(left) = left {
        for y in 0..size {
            for x in 0..size {
                dst[y * BPS + x] = left[y];
            }
        }
    } else {
        fill_block(dst, 129, size);
    }
}

/// Generate TM (TrueMotion) prediction for 16x16 luma block
/// Ported from libwebp's TrueMotion
///
/// left_with_corner[0] = top-left corner, left_with_corner[1..17] = left pixels
fn pred_luma16_tm(dst: &mut [u8], left_with_corner: Option<&[u8]>, top: Option<&[u8]>) {
    match (left_with_corner, top) {
        (Some(left), Some(top)) => {
            // Both borders: compute TrueMotion
            // left[0] is top-left corner, left[1..17] are left pixels
            let tl = i32::from(left[0]);
            for y in 0..16 {
                let l = i32::from(left[1 + y]);
                for x in 0..16 {
                    let t = i32::from(top[x]);
                    dst[y * BPS + x] = (l + t - tl).clamp(0, 255) as u8;
                }
            }
        }
        (Some(left), None) => {
            // Left only: use horizontal prediction
            horizontal_pred(dst, Some(&left[1..17]), 16);
        }
        (None, Some(top)) => {
            // Top only: use vertical prediction
            vertical_pred(dst, Some(top), 16);
        }
        (None, None) => {
            // Neither: fill with 129 (not 127 like VerticalPred default)
            fill_block(dst, 129, 16);
        }
    }
}

/// Generate all I16 predictions into yuv_p buffer
/// Ported from libwebp's VP8EncPredLuma16
///
/// left_with_corner: full y_left array where [0]=corner, [1..17]=left pixels
fn make_luma16_preds(yuv_p: &mut [u8], left_with_corner: Option<&[u8]>, top: Option<&[u8]>) {
    // DC prediction at I16DC16 (only needs left pixels, not corner)
    let left_only = left_with_corner.map(|l| &l[1..17]);
    pred_luma16_dc(&mut yuv_p[I16DC16..], left_only, top);

    // TM prediction at I16TM16 (needs corner at [0] and left pixels at [1..17])
    pred_luma16_tm(&mut yuv_p[I16TM16..], left_with_corner, top);

    // Note: V and H predictions not implemented since we only test DC and TM (MAX_INTRA16_MODE=2)
}

/// Generate DC prediction for 8x8 chroma block into BPS-strided buffer
/// Ported from libwebp's DCMode (size=8, round=8, shift=4)
fn pred_chroma8_dc(dst: &mut [u8], left: Option<&[u8]>, top: Option<&[u8]>) {
    let dc_val = match (top, left) {
        (Some(top), Some(left)) => {
            // Both borders: sum all 16 samples
            let mut dc: u32 = 0;
            for i in 0..8 {
                dc += u32::from(top[i]);
                dc += u32::from(left[i]);
            }
            ((dc + 8) >> 4) as u8
        }
        (Some(top), None) => {
            // Top only: sum 8 samples, double, then shift by 4
            let mut dc: u32 = 0;
            for i in 0..8 {
                dc += u32::from(top[i]);
            }
            dc += dc; // Double
            ((dc + 8) >> 4) as u8
        }
        (None, Some(left)) => {
            // Left only: sum 8 samples, double, then shift by 4
            let mut dc: u32 = 0;
            for i in 0..8 {
                dc += u32::from(left[i]);
            }
            dc += dc; // Double
            ((dc + 8) >> 4) as u8
        }
        (None, None) => {
            // No borders: use 128
            0x80u8
        }
    };

    // Fill 8x8 block
    for y in 0..8 {
        for x in 0..8 {
            dst[y * BPS + x] = dc_val;
        }
    }
}

/// Generate TM prediction for 8x8 chroma block
/// Ported from libwebp's TrueMotion
///
/// left_with_corner: [0]=corner, [1..9]=left pixels (matching u_left/v_left layout)
fn pred_chroma8_tm(dst: &mut [u8], left_with_corner: Option<&[u8]>, top: Option<&[u8]>) {
    match (left_with_corner, top) {
        (Some(left), Some(top)) => {
            // Both borders: compute TrueMotion
            // left[0] is top-left corner, left[1..9] are left pixels
            let tl = i32::from(left[0]);
            for y in 0..8 {
                let l = i32::from(left[1 + y]);
                for x in 0..8 {
                    let t = i32::from(top[x]);
                    dst[y * BPS + x] = (l + t - tl).clamp(0, 255) as u8;
                }
            }
        }
        (Some(left), None) => {
            // Left only: use horizontal prediction
            horizontal_pred(dst, Some(&left[1..9]), 8);
        }
        (None, Some(top)) => {
            // Top only: use vertical prediction
            vertical_pred(dst, Some(top), 8);
        }
        (None, None) => {
            // Neither: fill with 129
            fill_block(dst, 129, 8);
        }
    }
}

/// Generate all chroma predictions into yuv_p buffer
/// Ported from libwebp's VP8EncPredChroma8
///
/// Note: In libwebp, U and V predictions are interleaved in the buffer.
/// u_left_with_corner/v_left_with_corner: [0]=corner, [1..9]=left pixels
/// uv_top: U at [0..8], V at [8..16]
fn make_chroma8_preds(
    yuv_p: &mut [u8],
    u_left_with_corner: Option<&[u8]>,
    v_left_with_corner: Option<&[u8]>,
    uv_top: Option<&[u8]>,
) {
    // Extract U and V top borders if available
    let (u_top, v_top) = if let Some(uv_top) = uv_top {
        (Some(&uv_top[0..8]), Some(&uv_top[8..16]))
    } else {
        (None, None)
    };

    // For DC prediction, extract just the left pixels (no corner)
    let u_left_only = u_left_with_corner.map(|l| &l[1..9]);
    let v_left_only = v_left_with_corner.map(|l| &l[1..9]);

    // DC prediction for U at C8DC8
    pred_chroma8_dc(&mut yuv_p[C8DC8..], u_left_only, u_top);

    // DC prediction for V at C8DC8 + 8 (V is 8 pixels to the right of U)
    pred_chroma8_dc(&mut yuv_p[C8DC8 + 8..], v_left_only, v_top);

    // TM prediction for U at C8TM8 (needs corner)
    pred_chroma8_tm(&mut yuv_p[C8TM8..], u_left_with_corner, u_top);

    // TM prediction for V at C8TM8 + 8
    pred_chroma8_tm(&mut yuv_p[C8TM8 + 8..], v_left_with_corner, v_top);
}

//------------------------------------------------------------------------------
// Macroblock analysis
// Ported from libwebp's analysis_enc.c

/// Import a block of pixels into BPS-strided work buffer
/// Ported from libwebp's ImportBlock
fn import_block(src: &[u8], src_stride: usize, dst: &mut [u8], w: usize, h: usize, size: usize) {
    for y in 0..h {
        // Copy row
        for x in 0..w {
            dst[y * BPS + x] = src[y * src_stride + x];
        }
        // Replicate last pixel if width < size
        if w < size {
            let last_pixel = dst[y * BPS + w - 1];
            for x in w..size {
                dst[y * BPS + x] = last_pixel;
            }
        }
    }
    // Replicate last row if height < size
    for y in h..size {
        for x in 0..size {
            dst[y * BPS + x] = dst[(h - 1) * BPS + x];
        }
    }
}

/// Import vertical line into left border array
fn import_line(src: &[u8], src_stride: usize, dst: &mut [u8], len: usize, total_len: usize) {
    for i in 0..len {
        dst[i] = src[i * src_stride];
    }
    // Replicate last value
    let last = dst[len.saturating_sub(1).max(0)];
    for i in len..total_len {
        dst[i] = last;
    }
}

/// Analysis iterator state
/// Simplified version of libwebp's VP8EncIterator
pub struct AnalysisIterator {
    /// Current macroblock x position
    pub x: usize,
    /// Current macroblock y position
    pub y: usize,
    /// Image width in macroblocks
    pub mb_w: usize,
    /// Image height in macroblocks
    pub mb_h: usize,
    /// Picture width in pixels
    pub width: usize,
    /// Picture height in pixels
    pub height: usize,
    /// YUV input work buffer (BPS stride)
    pub yuv_in: Vec<u8>,
    /// Prediction work buffer (BPS stride)
    pub yuv_p: Vec<u8>,
    /// Left Y boundary samples (17 bytes: [-1] at index 0, [0..15] at indices 1..17)
    pub y_left: [u8; 17],
    /// Left U boundary samples (9 bytes)
    pub u_left: [u8; 9],
    /// Left V boundary samples (9 bytes)
    pub v_left: [u8; 9],
    /// Top Y boundary samples (mb_w * 16 + 4)
    pub y_top: Vec<u8>,
    /// Top UV boundary samples (mb_w * 16, interleaved U[0..8] V[8..16])
    pub uv_top: Vec<u8>,
}

impl AnalysisIterator {
    /// Create a new analysis iterator
    pub fn new(width: usize, height: usize) -> Self {
        let mb_w = (width + 15) / 16;
        let mb_h = (height + 15) / 16;

        Self {
            x: 0,
            y: 0,
            mb_w,
            mb_h,
            width,
            height,
            yuv_in: vec![0u8; YUV_SIZE_ENC],
            yuv_p: vec![0u8; PRED_SIZE_ENC],
            y_left: [129u8; 17],
            u_left: [129u8; 9],
            v_left: [129u8; 9],
            y_top: vec![127u8; mb_w * 16 + 4],
            uv_top: vec![127u8; mb_w * 16],
        }
    }

    /// Reset iterator to start
    pub fn reset(&mut self) {
        self.x = 0;
        self.y = 0;
        self.init_left();
        self.init_top();
    }

    /// Initialize left border to defaults
    fn init_left(&mut self) {
        let corner = if self.y > 0 { 129u8 } else { 127u8 };
        self.y_left[0] = corner;
        self.u_left[0] = corner;
        self.v_left[0] = corner;
        for i in 1..17 {
            self.y_left[i] = 129;
        }
        for i in 1..9 {
            self.u_left[i] = 129;
            self.v_left[i] = 129;
        }
    }

    /// Initialize top border to defaults
    fn init_top(&mut self) {
        self.y_top.fill(127);
        self.uv_top.fill(127);
    }

    /// Set iterator to start of row y
    pub fn set_row(&mut self, y: usize) {
        self.x = 0;
        self.y = y;
        self.init_left();
    }

    /// Import source samples into work buffer
    /// Ported from libwebp's VP8IteratorImport
    pub fn import(
        &mut self,
        y_src: &[u8],
        u_src: &[u8],
        v_src: &[u8],
        y_stride: usize,
        uv_stride: usize,
    ) {
        let x = self.x;
        let y = self.y;

        let y_offset = y * 16 * y_stride + x * 16;
        let uv_offset = y * 8 * uv_stride + x * 8;

        let w = (self.width - x * 16).min(16);
        let h = (self.height - y * 16).min(16);
        let uv_w = (w + 1) / 2;
        let uv_h = (h + 1) / 2;

        // Import Y
        import_block(
            &y_src[y_offset..],
            y_stride,
            &mut self.yuv_in[Y_OFF_ENC..],
            w,
            h,
            16,
        );

        // Import U
        import_block(
            &u_src[uv_offset..],
            uv_stride,
            &mut self.yuv_in[U_OFF_ENC..],
            uv_w,
            uv_h,
            8,
        );

        // Import V
        import_block(
            &v_src[uv_offset..],
            uv_stride,
            &mut self.yuv_in[V_OFF_ENC..],
            uv_w,
            uv_h,
            8,
        );

        // Import boundary samples
        if x == 0 {
            self.init_left();
        } else {
            // Top-left corner
            if y == 0 {
                self.y_left[0] = 127;
                self.u_left[0] = 127;
                self.v_left[0] = 127;
            } else {
                self.y_left[0] = y_src[y_offset - 1 - y_stride];
                self.u_left[0] = u_src[uv_offset - 1 - uv_stride];
                self.v_left[0] = v_src[uv_offset - 1 - uv_stride];
            }

            // Left column
            import_line(
                &y_src[y_offset - 1..],
                y_stride,
                &mut self.y_left[1..],
                h,
                16,
            );
            import_line(
                &u_src[uv_offset - 1..],
                uv_stride,
                &mut self.u_left[1..],
                uv_h,
                8,
            );
            import_line(
                &v_src[uv_offset - 1..],
                uv_stride,
                &mut self.v_left[1..],
                uv_h,
                8,
            );
        }

        // Top row
        if y == 0 {
            // First row: use 127
            for i in 0..16 {
                self.y_top[x * 16 + i] = 127;
            }
            for i in 0..8 {
                self.uv_top[x * 16 + i] = 127;
                self.uv_top[x * 16 + 8 + i] = 127;
            }
        } else {
            // Import from source
            for i in 0..w {
                self.y_top[x * 16 + i] = y_src[y_offset - y_stride + i];
            }
            // Replicate last pixel
            let last_y = self.y_top[x * 16 + w - 1];
            for i in w..16 {
                self.y_top[x * 16 + i] = last_y;
            }

            for i in 0..uv_w {
                self.uv_top[x * 16 + i] = u_src[uv_offset - uv_stride + i];
                self.uv_top[x * 16 + 8 + i] = v_src[uv_offset - uv_stride + i];
            }
            // Replicate
            let last_u = self.uv_top[x * 16 + uv_w - 1];
            let last_v = self.uv_top[x * 16 + 8 + uv_w - 1];
            for i in uv_w..8 {
                self.uv_top[x * 16 + i] = last_u;
                self.uv_top[x * 16 + 8 + i] = last_v;
            }
        }
    }

    /// Advance to next macroblock
    /// Returns true if more macroblocks remain
    pub fn next(&mut self) -> bool {
        self.x += 1;
        if self.x >= self.mb_w {
            self.set_row(self.y + 1);
        }
        self.y < self.mb_h
    }

    /// Check if iteration is done
    pub fn is_done(&self) -> bool {
        self.y >= self.mb_h
    }

    /// Get left boundary for Y with corner at index 0
    /// Returns full y_left array: [0]=corner, [1..17]=left pixels
    fn get_y_left_with_corner(&self) -> Option<&[u8]> {
        if self.x > 0 {
            Some(&self.y_left[..])
        } else {
            None
        }
    }

    /// Get top boundary for Y
    fn get_y_top(&self) -> Option<&[u8]> {
        if self.y > 0 {
            Some(&self.y_top[self.x * 16..self.x * 16 + 16])
        } else {
            None
        }
    }

    /// Get left boundary for U with corner at index 0
    /// Returns full u_left array: [0]=corner, [1..9]=left pixels
    fn get_u_left_with_corner(&self) -> Option<&[u8]> {
        if self.x > 0 {
            Some(&self.u_left[..])
        } else {
            None
        }
    }

    /// Get left boundary for V with corner at index 0
    /// Returns full v_left array: [0]=corner, [1..9]=left pixels
    fn get_v_left_with_corner(&self) -> Option<&[u8]> {
        if self.x > 0 {
            Some(&self.v_left[..])
        } else {
            None
        }
    }

    /// Get top boundary for UV (interleaved)
    fn get_uv_top(&self) -> Option<&[u8]> {
        if self.y > 0 {
            Some(&self.uv_top[self.x * 16..self.x * 16 + 16])
        } else {
            None
        }
    }

    /// Analyze best I16 mode and return alpha
    /// Ported from libwebp's MBAnalyzeBestIntra16Mode
    pub fn analyze_best_intra16_mode(&mut self) -> (i32, usize) {
        let mut best_alpha = -1i32;
        let mut best_mode = 0usize;

        // Extract boundary data before mutable borrow
        let has_left = self.x > 0;
        let has_top = self.y > 0;
        let y_left_copy: [u8; 17] = self.y_left;
        let y_top_start = self.x * 16;

        // Generate all predictions
        // Pass copies/slices to avoid borrow conflicts
        let y_left_opt = if has_left {
            Some(&y_left_copy[..])
        } else {
            None
        };
        let y_top_opt = if has_top {
            Some(&self.y_top[y_top_start..y_top_start + 16])
        } else {
            None
        };
        make_luma16_preds(&mut self.yuv_p, y_left_opt, y_top_opt);

        // Test DC (mode 0) and TM (mode 1)
        for mode in 0..MAX_INTRA16_MODE {
            let pred_offset = VP8_I16_MODE_OFFSETS[mode];

            // Collect histogram comparing yuv_in+Y_OFF vs yuv_p+mode_offset
            let histo = collect_histogram_with_offset(
                &self.yuv_in,
                Y_OFF_ENC,
                &self.yuv_p,
                pred_offset,
                0,
                16,
            );

            let alpha = histo.get_alpha();
            if alpha > best_alpha {
                best_alpha = alpha;
                best_mode = mode;
            }
        }

        (best_alpha, best_mode)
    }

    /// Analyze best UV mode and return alpha
    /// Ported from libwebp's MBAnalyzeBestUVMode
    pub fn analyze_best_uv_mode(&mut self) -> (i32, usize) {
        let mut best_alpha = -1i32;
        let mut smallest_alpha = i32::MAX;
        let mut best_mode = 0usize;

        // Extract boundary data before mutable borrow
        let has_left = self.x > 0;
        let has_top = self.y > 0;
        let u_left_copy: [u8; 9] = self.u_left;
        let v_left_copy: [u8; 9] = self.v_left;
        let uv_top_start = self.x * 16;

        // Generate all chroma predictions
        let u_left_opt = if has_left {
            Some(&u_left_copy[..])
        } else {
            None
        };
        let v_left_opt = if has_left {
            Some(&v_left_copy[..])
        } else {
            None
        };
        let uv_top_opt = if has_top {
            Some(&self.uv_top[uv_top_start..uv_top_start + 16])
        } else {
            None
        };
        make_chroma8_preds(&mut self.yuv_p, u_left_opt, v_left_opt, uv_top_opt);

        // Test DC (mode 0) and TM (mode 1)
        for mode in 0..MAX_UV_MODE {
            let pred_offset = VP8_UV_MODE_OFFSETS[mode];

            // Collect histogram for U+V blocks (blocks 16-24 in VP8DspScan)
            let histo = collect_histogram_with_offset(
                &self.yuv_in,
                U_OFF_ENC,
                &self.yuv_p,
                pred_offset,
                16,
                24,
            );

            let alpha = histo.get_alpha();
            if alpha > best_alpha {
                best_alpha = alpha;
            }
            // Best prediction mode is the one with smallest alpha
            if mode == 0 || alpha < smallest_alpha {
                smallest_alpha = alpha;
                best_mode = mode;
            }
        }

        (best_alpha, best_mode)
    }
}

/// Collect histogram with different source and prediction offsets
/// This allows comparing yuv_in at src_off with yuv_p at pred_off
fn collect_histogram_with_offset(
    src_buf: &[u8],
    src_base: usize,
    pred_buf: &[u8],
    pred_base: usize,
    start_block: usize,
    end_block: usize,
) -> DctHistogram {
    let mut distribution = [0u32; MAX_COEFF_THRESH + 1];

    for j in start_block..end_block {
        let scan_off = VP8_DSP_SCAN[j];
        let src_off = src_base + scan_off;
        let pred_off = pred_base + scan_off;

        let dct_out = forward_dct_4x4(&src_buf[src_off..], &pred_buf[pred_off..], BPS, BPS);

        for coeff in dct_out.iter() {
            let v = (coeff.unsigned_abs() >> 3) as usize;
            let clipped = v.min(MAX_COEFF_THRESH);
            distribution[clipped] += 1;
        }
    }

    DctHistogram::from_distribution(&distribution)
}

/// Analyze a single macroblock and return its alpha
/// Ported from libwebp's MBAnalyze
pub fn analyze_macroblock(it: &mut AnalysisIterator) -> u8 {
    let (best_alpha, _best_mode) = it.analyze_best_intra16_mode();
    let (best_uv_alpha, _uv_mode) = it.analyze_best_uv_mode();

    // Final susceptibility mix
    let alpha = (3 * best_alpha + best_uv_alpha + 2) >> 2;

    // Finalize: invert and clip
    final_alpha_value(alpha)
}

/// Run full analysis pass on image and return alpha histogram + per-MB alphas
/// Ported from libwebp's VP8EncAnalyze / DoSegmentsJob
pub fn analyze_image(
    y_src: &[u8],
    u_src: &[u8],
    v_src: &[u8],
    width: usize,
    height: usize,
    y_stride: usize,
    uv_stride: usize,
) -> (Vec<u8>, [u32; 256]) {
    let mut it = AnalysisIterator::new(width, height);
    it.reset();

    let total_mbs = it.mb_w * it.mb_h;
    let mut mb_alphas = vec![0u8; total_mbs];
    let mut alpha_histogram = [0u32; 256];

    let mut mb_idx = 0;
    loop {
        it.import(y_src, u_src, v_src, y_stride, uv_stride);

        let alpha = analyze_macroblock(&mut it);
        mb_alphas[mb_idx] = alpha;
        alpha_histogram[alpha as usize] += 1;

        mb_idx += 1;
        if !it.next() {
            break;
        }
    }

    (mb_alphas, alpha_histogram)
}

// Keep old function signatures for compatibility but mark as deprecated
#[allow(dead_code)]
#[deprecated(note = "Use analyze_image instead")]
pub fn collect_dct_histogram(
    _src: &[u8],
    _pred: &[u8],
    _src_stride: usize,
    _pred_stride: usize,
    _block_offsets: &[(usize, usize)],
) -> DctHistogram {
    DctHistogram::new()
}

#[allow(dead_code)]
#[deprecated(note = "Use analyze_image instead")]
pub fn compute_mb_alpha(_dct_coeffs: &[i32; 256]) -> u8 {
    128
}

/// Assign macroblocks to segments using k-means clustering on alpha values.
///
/// # Arguments
/// * `alphas` - Alpha histogram (count of macroblocks with each alpha value)
/// * `num_segments` - Number of segments to use (1-4)
///
/// # Returns
/// (centers, map, weighted_average) where:
/// - centers[i] = alpha center for segment i
/// - map[alpha] = segment index for that alpha value
/// - weighted_average = weighted average of centers (for SetSegmentAlphas)
pub fn assign_segments_kmeans(
    alphas: &[u32; 256],
    num_segments: usize,
) -> ([u8; NUM_SEGMENTS], [u8; 256], i32) {
    let num_segments = num_segments.min(NUM_SEGMENTS);
    let mut centers = [0u8; NUM_SEGMENTS];
    let mut map = [0u8; 256];

    // Find min and max alpha with non-zero count
    let mut min_a = 0usize;
    let mut max_a = MAX_ALPHA as usize;

    for (n, &count) in alphas.iter().enumerate() {
        if count > 0 {
            min_a = n;
            break;
        }
    }
    for n in (min_a..=MAX_ALPHA as usize).rev() {
        if alphas[n] > 0 {
            max_a = n;
            break;
        }
    }

    let range_a = max_a.saturating_sub(min_a);

    // Initialize centers evenly spread across the range
    for (k, center) in centers.iter_mut().enumerate().take(num_segments) {
        let n = 1 + 2 * k;
        *center = (min_a + (n * range_a) / (2 * num_segments)) as u8;
    }

    // K-means iterations
    let mut accum = [0u32; NUM_SEGMENTS];
    let mut dist_accum = [0u32; NUM_SEGMENTS];
    let mut weighted_average = 0i32;
    let mut total_weight = 0u32;

    for _ in 0..MAX_ITERS_K_MEANS {
        // Reset accumulators
        for i in 0..num_segments {
            accum[i] = 0;
            dist_accum[i] = 0;
        }

        // Assign each alpha value to nearest center
        let mut current_center = 0usize;
        for a in min_a..=max_a {
            if alphas[a] > 0 {
                // Find nearest center
                while current_center + 1 < num_segments {
                    let d_curr = (a as i32 - centers[current_center] as i32).abs();
                    let d_next = (a as i32 - centers[current_center + 1] as i32).abs();
                    if d_next < d_curr {
                        current_center += 1;
                    } else {
                        break;
                    }
                }
                map[a] = current_center as u8;
                dist_accum[current_center] += a as u32 * alphas[a];
                accum[current_center] += alphas[a];
            }
        }

        // Move centers to center of their clouds
        // Also compute weighted_average from final centers (as libwebp does)
        let mut displaced = 0i32;
        weighted_average = 0;
        total_weight = 0;
        for n in 0..num_segments {
            if accum[n] > 0 {
                let new_center = ((dist_accum[n] + accum[n] / 2) / accum[n]) as u8;
                displaced += (centers[n] as i32 - new_center as i32).abs();
                centers[n] = new_center;
                // libwebp computes weighted_average from final centers
                weighted_average += new_center as i32 * accum[n] as i32;
                total_weight += accum[n];
            }
        }

        // Early exit if centers have converged
        if displaced < 5 {
            break;
        }
    }

    // Finalize weighted_average with rounding (matching libwebp)
    if total_weight > 0 {
        weighted_average = (weighted_average + total_weight as i32 / 2) / total_weight as i32;
    } else {
        weighted_average = 128;
    }

    // Fill unused segments with last valid center
    for i in num_segments..NUM_SEGMENTS {
        centers[i] = centers[num_segments - 1];
    }

    (centers, map, weighted_average)
}

/// Compute per-segment quantization using libwebp's formula.
///
/// This matches VP8SetSegmentParams in libwebp/src/enc/quant_enc.c
///
/// # Arguments
/// * `base_quant` - Base quantizer index (0-127), computed from quality
/// * `segment_alpha` - Transformed alpha for this segment, in range [-127, 127]
///                     Computed as: 255 * (center - mid) / (max - min)
///                     Positive = easier to compress, negative = harder
/// * `sns_strength` - SNS strength (0-100), higher = more segment differentiation
///
/// # Returns
/// Adjusted quantizer index for this segment
pub fn compute_segment_quant(base_quant: u8, segment_alpha: i32, sns_strength: u8) -> u8 {
    // libwebp constant: scaling between SNS strength and quantizer modulation
    const SNS_TO_DQ: f64 = 0.9;

    // Amplitude of quantization modulation
    // amp = SNS_TO_DQ * sns_strength / 100 / 128
    let amp = SNS_TO_DQ * (sns_strength as f64) / 100.0 / 128.0;

    // Exponent for power-law modulation
    // segment_alpha is in [-127, 127] range
    // Positive alpha (easy) -> expn < 1 -> higher compression -> higher quant
    // Negative alpha (hard) -> expn > 1 -> lower compression -> lower quant
    let expn = 1.0 - amp * (segment_alpha as f64);

    // Ensure expn is positive (as asserted in libwebp)
    if expn <= 0.0 {
        return base_quant;
    }

    // Compression factor from base_quant
    // Since base_quant = 127 * (1 - c_base), we have c_base = 1 - base_quant/127
    let c_base = 1.0 - (base_quant as f64 / 127.0);

    // Apply power-law modulation
    let c = c_base.powf(expn);

    // Convert back to quantizer index
    let q = (127.0 * (1.0 - c)) as i32;
    q.clamp(0, 127) as u8
}

//------------------------------------------------------------------------------
// Tests

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_entropy_cost_table() {
        // Probability 128 (50%) should have cost ~256 (1 bit)
        assert!((VP8_ENTROPY_COST[128] as i32 - 256).abs() < 10);

        // Probability 255 (~100%) should have very low cost
        assert!(VP8_ENTROPY_COST[255] < 10);

        // Probability 1 (~0%) should have high cost
        assert!(VP8_ENTROPY_COST[1] > 1500);

        // Table should be monotonically decreasing
        for i in 1..256 {
            assert!(
                VP8_ENTROPY_COST[i] <= VP8_ENTROPY_COST[i - 1],
                "Entropy cost not monotonic at {}",
                i
            );
        }
    }

    #[test]
    fn test_bit_cost() {
        // Cost of 0 with prob 128 should equal cost of 1 with prob 128
        assert_eq!(vp8_bit_cost(false, 128), vp8_bit_cost(true, 128));

        // Cost of 0 with high prob should be low
        assert!(vp8_bit_cost(false, 250) < vp8_bit_cost(false, 128));

        // Cost of 1 with high prob should be high
        assert!(vp8_bit_cost(true, 250) > vp8_bit_cost(true, 128));
    }

    #[test]
    fn test_level_fixed_costs() {
        // Level 0 should have cost 0
        assert_eq!(VP8_LEVEL_FIXED_COSTS[0], 0);

        // Small levels should have lower cost than large levels
        assert!(VP8_LEVEL_FIXED_COSTS[1] < VP8_LEVEL_FIXED_COSTS[100]);
        assert!(VP8_LEVEL_FIXED_COSTS[100] < VP8_LEVEL_FIXED_COSTS[1000]);

        // Table should be correct size
        assert_eq!(VP8_LEVEL_FIXED_COSTS.len(), MAX_LEVEL + 1);
    }

    #[test]
    fn test_enc_bands() {
        // First 4 positions map to bands 0-3
        assert_eq!(VP8_ENC_BANDS[0], 0);
        assert_eq!(VP8_ENC_BANDS[1], 1);
        assert_eq!(VP8_ENC_BANDS[2], 2);
        assert_eq!(VP8_ENC_BANDS[3], 3);

        // Position 4 maps to band 6 (skip)
        assert_eq!(VP8_ENC_BANDS[4], 6);
    }

    #[test]
    fn test_fixed_costs_i16() {
        // DC should be cheapest
        assert!(FIXED_COSTS_I16[0] < FIXED_COSTS_I16[1]);
        assert!(FIXED_COSTS_I16[0] < FIXED_COSTS_I16[2]);
        assert!(FIXED_COSTS_I16[0] < FIXED_COSTS_I16[3]);

        // Values should match libwebp
        assert_eq!(FIXED_COSTS_I16[0], 663);
        assert_eq!(FIXED_COSTS_I16[1], 919);
        assert_eq!(FIXED_COSTS_I16[2], 872);
        assert_eq!(FIXED_COSTS_I16[3], 919);
    }

    #[test]
    fn test_fixed_costs_uv() {
        // DC should be cheapest
        assert!(FIXED_COSTS_UV[0] < FIXED_COSTS_UV[1]);

        // Values should match libwebp
        assert_eq!(FIXED_COSTS_UV[0], 302);
        assert_eq!(FIXED_COSTS_UV[1], 984);
        assert_eq!(FIXED_COSTS_UV[2], 439);
        assert_eq!(FIXED_COSTS_UV[3], 642);
    }

    #[test]
    fn test_fixed_costs_i4_context() {
        // DC after DC should be cheap
        let dc_after_dc = VP8_FIXED_COSTS_I4[0][0][0];
        assert!(dc_after_dc < 100);

        // Non-DC mode after DC should be more expensive
        let tm_after_dc = VP8_FIXED_COSTS_I4[0][0][1];
        assert!(tm_after_dc > dc_after_dc);

        // Table should be 10x10x10
        assert_eq!(VP8_FIXED_COSTS_I4.len(), NUM_BMODES);
        assert_eq!(VP8_FIXED_COSTS_I4[0].len(), NUM_BMODES);
        assert_eq!(VP8_FIXED_COSTS_I4[0][0].len(), NUM_BMODES);
    }

    #[test]
    fn test_lambda_calculation() {
        // At q=64 (medium quality)
        let q = 64u32;

        let lambda_i4 = calc_lambda_i4(q);
        let lambda_i16 = calc_lambda_i16(q);
        let lambda_uv = calc_lambda_uv(q);

        // lambda_i16 should be much larger than lambda_i4
        assert!(lambda_i16 > lambda_i4 * 50);

        // lambda_uv should be between i4 and i16
        assert!(lambda_uv > lambda_i4);
        assert!(lambda_uv < lambda_i16);

        // Values should match libwebp formulas
        assert_eq!(lambda_i4, (3 * 64 * 64) >> 7);
        assert_eq!(lambda_i16, 3 * 64 * 64);
        assert_eq!(lambda_uv, (3 * 64 * 64) >> 6);
    }

    #[test]
    fn test_i4_penalty() {
        let q = 64u32;
        let penalty = calc_i4_penalty(q);

        // Should be 1000 * q²
        assert_eq!(penalty, 1000 * 64 * 64);

        // At low q, penalty should be low
        assert!(calc_i4_penalty(10) < calc_i4_penalty(64));
    }

    #[test]
    fn test_rd_score() {
        // Zero SSE and zero cost = zero score
        assert_eq!(rd_score(0, 0, LAMBDA_I16), 0);

        // Only distortion
        assert_eq!(rd_score(100, 0, LAMBDA_I16), 100 * 256);

        // Only rate
        assert_eq!(rd_score(0, 663, LAMBDA_I16), 663 * 106);

        // Combined
        let expected = 1000 * 256 + u64::from(FIXED_COSTS_I16[0]) * 106;
        assert_eq!(rd_score(1000, FIXED_COSTS_I16[0], LAMBDA_I16), expected);
    }

    #[test]
    fn test_get_i4_mode_cost() {
        // Should return same as direct indexing
        assert_eq!(get_i4_mode_cost(0, 0, 0), VP8_FIXED_COSTS_I4[0][0][0]);
        assert_eq!(get_i4_mode_cost(5, 3, 7), VP8_FIXED_COSTS_I4[5][3][7]);
    }

    #[test]
    fn test_rd_trade_off() {
        let lambda = LAMBDA_I16;

        // DC mode with higher SSE
        let dc_sse = 1000u32;
        let dc_cost = FIXED_COSTS_I16[0];

        // V mode with lower SSE
        let v_sse = 500u32;
        let v_cost = FIXED_COSTS_I16[1];

        let dc_score = rd_score(dc_sse, dc_cost, lambda);
        let v_score = rd_score(v_sse, v_cost, lambda);

        // V should win with significantly lower SSE
        assert!(v_score < dc_score);
    }

    #[test]
    fn test_estimate_residual_cost() {
        // All zeros should have minimal cost
        let zeros = [0i32; 16];
        let cost_zeros = estimate_residual_cost(&zeros, 0);
        assert!(cost_zeros < 512, "Zero block cost should be ~1 bit");

        // Single non-zero DC coefficient
        let mut single_dc = [0i32; 16];
        single_dc[0] = 1;
        let cost_single = estimate_residual_cost(&single_dc, 0);
        assert!(
            cost_single > cost_zeros,
            "Non-zero coefficient should cost more"
        );

        // Higher coefficient values should cost more
        let mut large_coeff = [0i32; 16];
        large_coeff[0] = 100;
        let cost_large = estimate_residual_cost(&large_coeff, 0);
        assert!(
            cost_large > cost_single,
            "Large coefficient should cost more than small"
        );

        // More non-zero coefficients = higher cost
        let mut multiple = [0i32; 16];
        multiple[0] = 1;
        multiple[1] = 1;
        multiple[2] = 1;
        let cost_multiple = estimate_residual_cost(&multiple, 0);
        assert!(
            cost_multiple > cost_single,
            "Multiple coefficients should cost more"
        );

        // AC-only (first=1) should skip DC
        let mut dc_only = [0i32; 16];
        dc_only[0] = 100;
        let cost_ac_only = estimate_residual_cost(&dc_only, 1);
        assert!(
            cost_ac_only < estimate_residual_cost(&dc_only, 0),
            "AC-only should skip DC cost"
        );
    }

    #[test]
    fn test_rd_score_with_coeffs() {
        let sse = 1000u32;
        let mode_cost = FIXED_COSTS_I16[0];
        let coeff_cost = 2000u32;
        let lambda = LAMBDA_I16;

        let score = rd_score_with_coeffs(sse, mode_cost, coeff_cost, lambda);
        let expected = (sse as u64) * 256 + (mode_cost as u64 + coeff_cost as u64) * 106;
        assert_eq!(score, expected);

        // Without coeff cost should be lower
        let score_no_coeff = rd_score(sse, mode_cost, lambda);
        assert!(score_no_coeff < score);
    }

    #[test]
    fn test_trellis_basic() {
        // Create a Y1 matrix at q=50
        let matrix = VP8Matrix::new(50, 50, MatrixType::Y1);

        // Test case 1: DC dominant block (natural order)
        let block = [
            500i32, 50, 25, 10, // row 0
            5, 3, 2, 1, // row 1
            0, 0, 0, 0, // row 2
            0, 0, 0, 0, // row 3
        ];

        let mut coeffs = block;
        let mut trellis_out = [0i32; 16];

        // Lambda for i4: (7 * 50^2) >> 3 = 2187
        let lambda = 2187u32;

        // Create level costs for test
        let mut level_costs = LevelCosts::new();
        level_costs.calculate(&crate::vp8_common::COEFF_PROBS);

        let trellis_nz = trellis_quantize_block(
            &mut coeffs,
            &mut trellis_out,
            &matrix,
            lambda,
            0,
            &level_costs,
            3, // I4 type
            0, // initial context
        );

        // Simple quantization for comparison
        let mut simple_out = [0i32; 16];
        for i in 0..16 {
            let j = VP8_ZIGZAG[i]; // Convert zigzag position to natural
            simple_out[i] = matrix.quantize_coeff(block[j], j);
        }

        eprintln!("Test case 1: DC dominant");
        eprintln!("  Input (natural order):  {:?}", block);
        eprintln!("  Simple (zigzag order):  {:?}", simple_out);
        eprintln!("  Trellis (zigzag order): {:?}", trellis_out);
        eprintln!("  Trellis has_nz: {}", trellis_nz);

        // Both should produce non-zero DC coefficient
        assert!(simple_out[0] != 0, "Simple should have non-zero DC");

        // Check that trellis produces reasonable output
        // It may zero more aggressively but DC should usually be preserved for large values
        eprintln!();
    }

    #[test]
    fn test_trellis_vs_simple() {
        // Create a Y1 matrix at q=30
        let matrix = VP8Matrix::new(30, 30, MatrixType::Y1);

        // Block with clear signal
        let block = [
            300i32, 0, 0, 0,
            0, 0, 0, 0,
            0, 0, 0, 0,
            0, 0, 0, 0,
        ];

        let mut coeffs = block;
        let mut trellis_out = [0i32; 16];
        let lambda = ((7 * 30 * 30) >> 3) as u32;

        let mut level_costs = LevelCosts::new();
        level_costs.calculate(&crate::vp8_common::COEFF_PROBS);

        let _ = trellis_quantize_block(
            &mut coeffs,
            &mut trellis_out,
            &matrix,
            lambda,
            0,
            &level_costs,
            3, // I4 type
            0, // initial context
        );

        // Simple
        let simple_dc = matrix.quantize_coeff(block[0], 0);

        eprintln!("Single DC coefficient test:");
        eprintln!("  Input DC: {}", block[0]);
        eprintln!("  Simple DC: {}", simple_dc);
        eprintln!("  Trellis DC: {}", trellis_out[0]);

        // For a large DC coefficient, trellis should preserve it
        assert!(
            trellis_out[0] != 0 || simple_dc == 0,
            "Trellis zeroed DC but simple didn't"
        );
    }

    /// Test demonstrating why trellis is currently disabled.
    ///
    /// The trellis uses simplified fixed costs (level_cost) that don't account for
    /// probability-dependent costs. This causes it to favor non-zero coefficients
    /// even when the simple quantizer would produce zero.
    ///
    /// Example: For a coefficient value of -17 with quantizer 30:
    /// - Simple quantization (with bias): produces 0
    /// - Trellis (with neutral bias): computes level0=0, but then considers level=1
    ///   because the distortion reduction outweighs the fixed rate cost.
    ///
    /// In libwebp, VP8LevelCost uses full probability tables that make coding zeros
    /// "cheaper" in certain contexts, which prevents this issue.
    #[test]
    fn test_trellis_known_issue() {
        // Reproduce the issue: trellis produces non-zero where simple produces zero
        let matrix = VP8Matrix::new(27, 30, MatrixType::Y1);

        // Block with small coefficient at position 4 (-17)
        let block = [
            20i32, -8, 0, 0, -17, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        ];

        // Simple quantization
        let mut simple_out = [0i32; 16];
        for i in 0..16 {
            let j = VP8_ZIGZAG[i];
            simple_out[i] = matrix.quantize_coeff(block[j], j);
        }

        // Trellis quantization with probability-dependent costs
        let mut coeffs = block;
        let mut trellis_out = [0i32; 16];
        let lambda = 787u32;

        let mut level_costs = LevelCosts::new();
        level_costs.calculate(&crate::vp8_common::COEFF_PROBS);

        let _ = trellis_quantize_block(
            &mut coeffs,
            &mut trellis_out,
            &matrix,
            lambda,
            0,
            &level_costs,
            3, // I4 type
            0, // initial context
        );

        // Simple produces zeros for small coefficients
        assert_eq!(simple_out[2], 0, "Simple should quantize position 2 to 0");
        // With probability-dependent costs, trellis should now also produce 0
        // because the higher cost of coding a non-zero coefficient outweighs the
        // distortion benefit
        eprintln!("trellis_out[2] = {}", trellis_out[2]);
        // Note: if this still produces -1, there may be more tuning needed
    }

    #[test]
    fn test_trellis_quality75() {
        // Quality 75 -> quant_index 26
        // DC=27, AC=30
        let matrix = VP8Matrix::new(27, 30, MatrixType::Y1);

        // Test with realistic gradient image transform coefficients
        // A gradient block might have DC ~1000 and small AC values
        let blocks = [
            // Block 1: Strong DC, some AC
            [1000i32, 100, 50, 25, 15, 10, 5, 3, 2, 1, 0, 0, 0, 0, 0, 0],
            // Block 2: Medium DC
            [500, 50, 25, 10, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
            // Block 3: Weak signal
            [100, 20, 10, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
            // Block 4: Near zero
            [30, 5, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        ];

        let lambda = ((7 * 30 * 30) >> 3) as u32; // 787
        eprintln!("Lambda: {}", lambda);

        let mut level_costs = LevelCosts::new();
        level_costs.calculate(&crate::vp8_common::COEFF_PROBS);

        for (i, block) in blocks.iter().enumerate() {
            let mut coeffs = *block;
            let mut trellis_out = [0i32; 16];
            let _ = trellis_quantize_block(
                &mut coeffs,
                &mut trellis_out,
                &matrix,
                lambda,
                0,
                &level_costs,
                3, // I4 type
                0, // initial context
            );

            // Simple quantization
            let mut simple_out = [0i32; 16];
            for j in 0..16 {
                let zz = VP8_ZIGZAG[j];
                simple_out[j] = matrix.quantize_coeff(block[zz], zz);
            }

            eprintln!("\nBlock {}: input DC={}", i + 1, block[0]);
            eprintln!("  Simple:  {:?}", &simple_out[..8]);
            eprintln!("  Trellis: {:?}", &trellis_out[..8]);

            // Check SSE difference
            let simple_sse: i64 = (0..16)
                .map(|j| {
                    let zz = VP8_ZIGZAG[j];
                    let orig = block[zz] as i64;
                    let recon = simple_out[j] as i64 * matrix.q[zz] as i64;
                    (orig - recon) * (orig - recon)
                })
                .sum();

            let trellis_sse: i64 = (0..16)
                .map(|j| {
                    let zz = VP8_ZIGZAG[j];
                    let orig = block[zz] as i64;
                    let recon = trellis_out[j] as i64 * matrix.q[zz] as i64;
                    (orig - recon) * (orig - recon)
                })
                .sum();

            eprintln!("  Simple SSE: {}, Trellis SSE: {}", simple_sse, trellis_sse);
        }
    }

    /// Diagnostic test to capture all data needed to debug trellis calibration.
    /// Run with: cargo test --release test_trellis_diagnostic -- --nocapture
    #[test]
    fn test_trellis_diagnostic() {
        use crate::vp8_common::COEFF_PROBS;

        let matrix = VP8Matrix::new(27, 30, MatrixType::Y1);
        let mut level_costs = LevelCosts::new();
        level_costs.calculate(&COEFF_PROBS);

        // Test block that showed issues: small coefficient at position 4
        let block = [20i32, -8, 0, 0, -17, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0];
        let lambda = 787u32;
        let ctype = 3usize; // I4
        let ctx0 = 0usize;

        eprintln!("\n=== TRELLIS DIAGNOSTIC ===");
        eprintln!("Lambda: {}", lambda);
        eprintln!("Block type: {} (I4)", ctype);
        eprintln!("Initial context: {}", ctx0);
        eprintln!("Input block (natural order): {:?}", block);

        // Show quantization parameters
        eprintln!("\nQuantization parameters:");
        eprintln!("  DC q={}, iq={}, bias={}", matrix.q[0], matrix.iq[0], matrix.bias[0]);
        eprintln!("  AC q={}, iq={}, bias={}", matrix.q[1], matrix.iq[1], matrix.bias[1]);

        // Show cost table values for position 0, contexts 0,1,2
        eprintln!("\nCost tables for position 0 (levels 0,1,2):");
        for ctx in 0..3 {
            let costs = level_costs.get_cost_table(ctype, 0, ctx);
            eprintln!("  ctx={}: level0={}, level1={}, level2={}",
                ctx, costs[0], costs[1], costs[2]);
        }

        // Simple quantization
        let mut simple_out = [0i32; 16];
        for i in 0..16 {
            let j = VP8_ZIGZAG[i];
            simple_out[i] = matrix.quantize_coeff(block[j], j);
        }
        eprintln!("\nSimple quantization (zigzag): {:?}", simple_out);

        // Per-coefficient analysis
        eprintln!("\nPer-coefficient analysis:");
        eprintln!("{:>3} {:>6} {:>6} {:>6} {:>10} {:>10} {:>10}",
            "pos", "input", "simple", "level0", "cost_l0", "cost_l1", "dist_diff");

        for n in 0..8 {
            let j = VP8_ZIGZAG[n];
            let coeff = block[j];
            let q = matrix.q[j] as i32;
            let iq = matrix.iq[j];

            // Compute level0 (base quantization with neutral bias)
            let sign = coeff < 0;
            let abs_coeff = if sign { -coeff } else { coeff };
            let level0 = quantdiv(abs_coeff as u32, iq, quantization_bias(0x00)).min(MAX_LEVEL as i32);

            // Get cost table (assume ctx=0 for simplicity)
            let costs = level_costs.get_cost_table(ctype, n, 0);

            // Cost for level0 and level0+1
            let cost_l0 = VP8_LEVEL_FIXED_COSTS[level0 as usize] as u32
                + costs[level0.min(MAX_VARIABLE_LEVEL as i32) as usize] as u32
                + if level0 > 0 { 256 } else { 0 };
            let cost_l1 = VP8_LEVEL_FIXED_COSTS[(level0 + 1).min(MAX_LEVEL as i32) as usize] as u32
                + costs[(level0 + 1).min(MAX_VARIABLE_LEVEL as i32) as usize] as u32
                + 256; // always non-zero

            // Distortion difference if we use level0+1 instead of level0
            let err0 = abs_coeff - level0 * q;
            let err1 = abs_coeff - (level0 + 1) * q;
            let dist_diff = err1 * err1 - err0 * err0;

            eprintln!("{:>3} {:>6} {:>6} {:>6} {:>10} {:>10} {:>10}",
                n, coeff, simple_out[n], level0, cost_l0, cost_l1, dist_diff);
        }

        // RD decision analysis
        eprintln!("\nRD decision at lambda={}:", lambda);
        eprintln!("For level0 -> level0+1: chose higher level if:");
        eprintln!("  lambda * (cost_l1 - cost_l0) < 256 * (dist0 - dist1)");
        eprintln!("  {} * cost_delta < 256 * dist_delta", lambda);

        // EOB cost analysis
        eprintln!("\nEOB cost analysis (approximate=128 vs actual p[0]):");
        let eob_approx = vp8_bit_cost(false, 128);
        for band in 0..8 {
            let p0_0 = COEFF_PROBS[ctype][band][0][0];
            let p0_1 = COEFF_PROBS[ctype][band][1][0];
            let p0_2 = COEFF_PROBS[ctype][band][2][0];
            let eob_0 = vp8_bit_cost(false, p0_0);
            let eob_1 = vp8_bit_cost(false, p0_1);
            let eob_2 = vp8_bit_cost(false, p0_2);
            eprintln!(
                "  band {}: ctx0: p0={:3} eob={:3} (diff={:+4}), ctx1: p0={:3} eob={:3} (diff={:+4}), ctx2: p0={:3} eob={:3} (diff={:+4})",
                band,
                p0_0, eob_0, eob_0 as i32 - eob_approx as i32,
                p0_1, eob_1, eob_1 as i32 - eob_approx as i32,
                p0_2, eob_2, eob_2 as i32 - eob_approx as i32
            );
        }

        // Run trellis
        let mut coeffs = block;
        let mut trellis_out = [0i32; 16];
        let _ = trellis_quantize_block(
            &mut coeffs,
            &mut trellis_out,
            &matrix,
            lambda,
            0,
            &level_costs,
            ctype,
            ctx0,
        );
        eprintln!("\nTrellis output (zigzag): {:?}", trellis_out);

        // Show differences
        eprintln!("\nDifferences (simple vs trellis):");
        for n in 0..16 {
            if simple_out[n] != trellis_out[n] {
                eprintln!("  pos {}: simple={}, trellis={}", n, simple_out[n], trellis_out[n]);
            }
        }
    }

    /// Compare our trellis with libwebp's output using matching input.
    /// Uses values from libwebp debug log.
    /// Run with: cargo test --release test_trellis_vs_libwebp -- --nocapture
    #[test]
    fn test_trellis_vs_libwebp() {
        use crate::vp8_common::COEFF_PROBS;

        // From libwebp debug log:
        // === BLOCK 0: type=3 ctx0=0 lambda=840 first=0 ===
        // input: -282 6 3 -4 -3 -11 -4 -2 5 3 4 -1 2 -2 -3 -1
        // q: 25 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31
        // iq: 5242 4228 4228 4228 4228 4228 4228 4228 4228 4228 4228 4228 4228 4228 4228 4228
        // last=1 thresh=240 last_proba=202 skip_cost=89 skip_score=74760
        // init: ctx0=0 init_rate=576 init_score=483840
        // RESULT: out: -11 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0

        let mut level_costs = LevelCosts::new();
        level_costs.calculate(&COEFF_PROBS);

        // Match libwebp's matrix values exactly
        let mut matrix = VP8Matrix::new(25, 31, MatrixType::Y1);
        // Override iq values to match libwebp
        matrix.iq[0] = 5242;
        for i in 1..16 {
            matrix.iq[i] = 4228;
        }

        // Input coefficients (NOTE: these are already in natural/raster order in libwebp)
        // libwebp's "input" is coefficients[j] where j = kZigzag[n], so already in natural order
        let input = [-282i32, 6, 3, -4, -3, -11, -4, -2, 5, 3, 4, -1, 2, -2, -3, -1];

        let lambda = 840u32;
        let ctype = 3usize; // TYPE_I4_AC
        let ctx0 = 0usize;
        let first = 0usize;

        eprintln!("\n=== TRELLIS VS LIBWEBP ===");
        eprintln!("lambda={}, ctype={} (I4), ctx0={}, first={}", lambda, ctype, ctx0, first);

        // Check skip and init costs
        let skip_cost = level_costs.get_skip_eob_cost(ctype, first, ctx0);
        let init_cost = level_costs.get_init_cost(ctype, first, ctx0);
        let skip_score = rd_score_trellis(lambda, skip_cost as i64, 0);
        let init_score = rd_score_trellis(lambda, init_cost as i64, 0);

        eprintln!("\nCost comparison:");
        eprintln!("  skip_cost: rust={} libwebp=89", skip_cost);
        eprintln!("  skip_score: rust={} libwebp=74760", skip_score);
        eprintln!("  init_cost: rust={} libwebp=576", init_cost);
        eprintln!("  init_score: rust={} libwebp=483840", init_score);

        // Calculate thresh like libwebp
        let thresh = (matrix.q[1] as i64 * matrix.q[1] as i64 / 4) as i32;
        eprintln!("\nthresh: rust={} libwebp=240", thresh);

        // Run trellis
        let mut coeffs = input;
        let mut trellis_out = [0i32; 16];
        let _has_nz = trellis_quantize_block(
            &mut coeffs,
            &mut trellis_out,
            &matrix,
            lambda,
            first,
            &level_costs,
            ctype,
            ctx0,
        );

        eprintln!("\nOutput comparison:");
        eprintln!("  rust:    {:?}", trellis_out);
        eprintln!("  libwebp: [-11, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]");

        // Assert match
        let expected = [-11i32, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0];
        assert_eq!(trellis_out, expected, "Trellis output should match libwebp");
    }
}
